<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Laura Botzet" />


<title></title>

<script src="library/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="library/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="library/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="library/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="library/bootstrap-3.3.5/shim/respond.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="library/highlight/default.css"
      type="text/css" />
<script src="library/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->
<script src="library/navigation-1.1/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="fluid-row" id="header">




</div>


<div id="library" class="section level2">
<h2>Library</h2>
<pre class="r"><code>library(formr)
library(devtools)
library(haven)
library(tidyr)
library(ggplot2)
library(stringr)
library(dplyr)</code></pre>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:formr&#39;:
## 
##     first, last</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>library(GPArotation)</code></pre>
</div>
<div id="helper" class="section level2">
<h2>Helper</h2>
<pre class="r"><code>### Function to calculate the birthdate out of all available informations for one individual
all_available_info_birth_date = function(byear, bmonth, bday = NULL) {
  if(!is.null(bday)) {
    bday = paste0(&quot;-&quot;, bday)
  } else {
    bday = &quot;&quot;
  }
  ifelse(is.na(byear), NA,
         paste0(byear, &quot;-&quot;, bmonth, bday))
  # can yield 2016-NA-NA
  #           2016-01-NA
  #           2016-01-01
  #           2016-01
}

##### Function to calculate the birthorder based on the siblings still alive at the time of birth
older_sibs_alive_and_dependent = function(byear, dyear) {
    sibs = length(byear)
    older_sibs_alive_and_dependent = integer(length=sibs) + 1
    for(i in 1:sibs) {
        older_sibs = byear &lt;= byear[i] # not using &lt; because of twins
        older_sibs[i] = F # minus self
        my_sibs = sum(older_sibs,na.rm = T) # minus self
        if(my_sibs &gt; 0) {
            sib_births = byear[ which(older_sibs) ]
            sib_deaths = dyear[ which(older_sibs) ]
            my_sibs = my_sibs -
                sum(
                    # sib_births &lt; (byear[i] - 5) | # others born more than 5y earlier than me  # 10 seconds of 17
                        (sib_deaths &lt;= byear[i]) # died before my birth
                ,na.rm=T)
            older_sibs_alive_and_dependent[i] = my_sibs
        }
    }
    older_sibs_alive_and_dependent
}</code></pre>
</div>
<div id="load-data" class="section level2">
<h2>Load data</h2>
<pre class="r"><code>### Informations about individuals living in the household in 2014/2015
## All Individuals living in the household
bk_ar1 = read_dta(&quot;data/hh14_all_dta/bk_ar1.dta&quot;) # Book K, Section ar
# compute father pidlink
bk_ar1 = left_join(bk_ar1, bk_ar1 %&gt;% select(hhid14_9, pid14, pidlink) %&gt;% rename(ar10 = pid14, father_pidlink = pidlink), by = c(&quot;hhid14_9&quot;, &quot;ar10&quot;))
# compute mother pidlink
bk_ar1 = left_join(bk_ar1, bk_ar1 %&gt;% select(hhid14_9, pid14, pidlink) %&gt;% rename(ar11 = pid14, mother_pidlink = pidlink), by = c(&quot;hhid14_9&quot;, &quot;ar11&quot;))

### Informations from IFLS wave 5 to link data to earlier waves:
ptrack = read_dta(&quot;data/hh14_all_dta/ptrack.dta&quot;) # Traking informations

## Additional information from mothers (ever-maried women aged 15 - 57) about children that do not live in the household anymore
# biological children
b4_ba6 = read_dta(&quot;data/hh14_all_dta/b4_ba6.dta&quot;) # Book 4, Section ba6
# adopted children
b4_bx6 = read_dta(&quot;data/hh14_all_dta/b4_bx6.dta&quot;) # Book 4, Section bx6
# Book used to find out who completed book 4 (to find out for which mothers we have all informations about their children)
b4_cov = read_dta(&quot;data/hh14_all_dta/b4_cov.dta&quot;) # Book 4, Section cov


## Additional informations from fathers (and mothers who did not complete Book 4) about children that do not live in the household anymore
# biological and adopted children
b3b_ba6 = read_dta(&quot;data/hh14_all_dta/b3b_ba6.dta&quot;) # Book 3b, Section ba6
# Book used to find out who completed book 3b (to find out for which fathers/mothers we have all informations about their children)
b3b_cov = read_dta(&quot;data/hh14_all_dta/b3b_cov.dta&quot;) # Book 3b, Section cov

### Pregnancy Informations from mother
## Wave 5 - 2014
w5_pregnancy = read_dta(&quot;data/hh14_all_dta/b4_ch1.dta&quot;) # Book 4, Section ch
## Wave 4 - 2007
w4_pregnancy = read_dta(&quot;data/hh07_all_dta/b4_ch1.dta&quot;) # Book 4, Section ch
## Wave 3 - 2000
w3_pregnancy = read_dta(&quot;data/hh00_all_dta/b4_ch1.dta&quot;) # Book 4, Section ch
## Wave 2 - 1997
w2_pregnancy = read_dta(&quot;data/hh97dta/b4_ch1.dta&quot;) # Book 4, Section ch
## Wave 1 - 1993
w1_pregnancy = read_dta(&quot;data/hh93dta/buk4ch1.dta&quot;) # Book 4, Section ch

### IQ Information
ek_ek2 = read_dta(&quot;data/hh14_all_dta/ek_ek2.dta&quot;) # Book ek2
# additional information (counting backwards, adaptive testing) for adults
b3b_cob = read_dta(&quot;data/hh14_all_dta/b3b_cob.dta&quot;) # Book 3b, Section cob
b3b_co1 = read_dta(&quot;data/hh14_all_dta/b3b_co1.dta&quot;) # Book 3b, Section co1
### Personality Information (only for adults)
b3b_psn = read_dta(&quot;data/hh14_all_dta/b3b_psn.dta&quot;) # Book 3b, Section psn

### Risk taking
b3a_si = read_dta(&quot;data/hh14_all_dta/b3a_si.dta&quot;) # Book 3b, Section si</code></pre>
</div>
<div id="pregnancy-informations" class="section level2">
<h2>Pregnancy informations</h2>
<pre class="r"><code>## Select data
w5_pregnancy = w5_pregnancy %&gt;% select(pidlink, ch06, ch08, ch09day, ch09mth, ch09yr)
w4_pregnancy = w4_pregnancy %&gt;% select(pidlink, ch06, ch08, ch09day, ch09mth, ch09yr)
w3_pregnancy = w3_pregnancy %&gt;% select(pidlink, ch06, ch08, ch09day, ch09mth, ch09yr)
w2_pregnancy = w2_pregnancy %&gt;% select(pidlink, ch06, ch08, ch09day, ch09mth, ch09yr)
w1_pregnancy = w1_pregnancy %&gt;% select(pidlink, ch06, ch08, ch09day, ch09mth, ch09yr)
# In the first wave the year is named wrong
w1_pregnancy = w1_pregnancy %&gt;%
  filter(ch09yr &lt;=93)
w1_pregnancy$ch09yr = as.numeric(str_c(&quot;19&quot;, w1_pregnancy$ch09yr))

## Combine data
pregnancy = bind_rows(w1_pregnancy, w2_pregnancy, w3_pregnancy, w4_pregnancy, w5_pregnancy)
length(unique(pregnancy$pidlink))</code></pre>
<pre><code>## [1] 16035</code></pre>
<pre class="r"><code>## Rename Variables
pregnancy = pregnancy %&gt;% rename(lifebirths = ch06, gender = ch08, birth_day = ch09day, birth_month = ch09mth, birth_year = ch09yr, mother_pidlink = pidlink) # pregnancy$lifebirths values: 1 = still pregnant, 2 = livebirth, 3 = still birth, 4 = misscarriage

## Set values as NA that are missing
pregnancy$birth_day[ pregnancy$birth_day&gt;31] = NA
pregnancy$birth_month[ pregnancy$birth_month&gt;12] = NA
pregnancy$birth_year[ pregnancy$birth_year&gt;2016] = NA
pregnancy$birth_day[ is.nan(pregnancy$birth_day) ] = NA
pregnancy$birth_month[ is.nan(pregnancy$birth_month) ] = NA
pregnancy$birth_year[ is.nan(pregnancy$birth_year)] = NA


pregnancy = pregnancy %&gt;%
  mutate(birthdate = all_available_info_birth_date(birth_year, birth_month, birth_day),
         mother_birthdate = str_c(mother_pidlink, &quot;-&quot;, birthdate))

##remove all with missing mother_birthdate
pregnancy = pregnancy %&gt;%
  filter(!is.na(mother_birthdate))


### Remove all families with multiple births:
## Mark multpile births
pregnancy = pregnancy %&gt;%
  mutate(multiple_birth = ifelse(duplicated(mother_birthdate), 1, 0))
## All women that ever had multiple births
twinmothers = pregnancy %&gt;%
  filter(multiple_birth == 1)
length(unique(twinmothers$mother_pidlink)) ## number of families that have to be excluded due to multiple births</code></pre>
<pre><code>## [1] 2566</code></pre>
<pre class="r"><code>pregnancy = pregnancy %&gt;%
    filter(!(mother_pidlink %in% twinmothers$mother_pidlink))</code></pre>
</div>
<div id="uterus-birthorder-and-maternal-sibling-count" class="section level2">
<h2>Uterus Birthorder and maternal sibling count</h2>
<pre class="r"><code>### Birthorder calculations
## Biological Uterus Birthorder calculations with all pregnancies:
pregnancy1 = pregnancy %&gt;%
  group_by(mother_pidlink) %&gt;%
  mutate(birthorder_uterus_preg = min_rank(birthdate),
         sibling_count_uterus_preg = sum(!is.na(birthdate)))
         
## Biological Uterus Birthorder calculations with all births:
pregnancy2 = pregnancy %&gt;%
  filter(lifebirths == 2) %&gt;%
  group_by(mother_pidlink) %&gt;%
    mutate(birthorder_uterus_alive = min_rank(birthdate),
           sibling_count_uterus_alive = sum(!is.na(birthdate)))

pregnancy2 = pregnancy2 %&gt;% select(mother_birthdate, birthorder_uterus_alive, sibling_count_uterus_alive)</code></pre>
<pre><code>## Adding missing grouping variables: `mother_pidlink`</code></pre>
<pre class="r"><code>### 3040 individuals are removed because of death before/during birth

### Combine birthorder data
pregnancy = left_join(pregnancy1, pregnancy2, by=&quot;mother_birthdate&quot;)

### Graphs
## Biological Birthorder - Uterus_Pregnancies
qplot(pregnancy$birthorder_uterus_preg)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="1_data_import_files/figure-html/Uterus%20birthorder%20and%20maternal%20sibling%20count-1.png" width="672" /></p>
<pre class="r"><code>ggplot(pregnancy, aes(x=sibling_count_uterus_preg, y=birthorder_uterus_preg)) + geom_jitter()</code></pre>
<p><img src="1_data_import_files/figure-html/Uterus%20birthorder%20and%20maternal%20sibling%20count-2.png" width="672" /></p>
<pre class="r"><code>## Biological Birthorder - Uterus_Births
qplot(pregnancy$birthorder_uterus_alive)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 3040 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/Uterus%20birthorder%20and%20maternal%20sibling%20count-3.png" width="672" /></p>
<pre class="r"><code>ggplot(pregnancy, aes(x=sibling_count_uterus_alive, y=birthorder_uterus_alive)) + geom_jitter()</code></pre>
<pre><code>## Warning: Removed 3040 rows containing missing values (geom_point).</code></pre>
<p><img src="1_data_import_files/figure-html/Uterus%20birthorder%20and%20maternal%20sibling%20count-4.png" width="672" /></p>
<pre class="r"><code>## Bio: Uterus_preg vs. Uterus_Births
ggplot(pregnancy, aes(x=birthorder_uterus_preg, y=birthorder_uterus_alive)) + geom_jitter()</code></pre>
<pre><code>## Warning: Removed 3040 rows containing missing values (geom_point).</code></pre>
<p><img src="1_data_import_files/figure-html/Uterus%20birthorder%20and%20maternal%20sibling%20count-5.png" width="672" /></p>
<pre class="r"><code># The birth_order_alive is always lower, which makes sense, becaus not live births (miscarriage, still births are excluded)</code></pre>
</div>
<div id="select-individual-data" class="section level2">
<h2>Select individual data</h2>
<pre class="r"><code>### Individuals
individuals = bk_ar1 %&gt;% select(hhid14_9, pidlink, father_pidlink, mother_pidlink, ar01a, ar02b, ar10, ar11, ar07, ar08day, ar08mth, ar08yr, ar09, ar18eyr, ar18emth)
#Rename variables to make it easier
individuals = rename(individuals, relation_to_HH_head = ar02b, fatherID = ar10, motherID = ar11, sex = ar07, age = ar09, status = ar01a, death_yr = ar18eyr, death_month = ar18emth) 
# Remove duplicats (some people are mentioned in two households, e.g. because they moved in the last 12 months)
individuals = individuals %&gt;% distinct(pidlink, .keep_all = TRUE)
individuals_unchanged = individuals

## people whose parents can not be identified have to be marked as NA:
individuals$fatherID[ individuals$fatherID&gt;50] = NA
individuals$motherID[ individuals$motherID&gt;50] = NA


## create mother_father_number that should be identical for all siblings in one family that share the same parents
individuals = individuals %&gt;% mutate(
  mother_father_dyad = stringr::str_c(father_pidlink, mother_pidlink)
) # father_pidlink and mother_pidlink; if one is missing = NA


## Create date of birth
#Set all variables missing that have not been reported:
individuals$ar08day[ individuals$ar08day&gt;31] = NA
individuals$ar08mth[ individuals$ar08mth&gt;12] = NA
individuals$ar08yr[ individuals$ar08yr&gt;2016] = NA
individuals$ar08day[ is.nan(individuals$ar08day) ] = NA
individuals$ar08mth[ is.nan(individuals$ar08mth) ] = NA
individuals$ar08yr[ is.nan(individuals$ar08yr)] = NA
individuals$death_month[ individuals$death_month&gt;12] = NA
individuals$death_yr[ individuals$death_yr&gt;2016] = NA
individuals$death_month[ is.nan(individuals$death_month) ] = NA
individuals$death_yr[ is.nan(individuals$death_yr)] = NA

## Create variable that contains pidlink of mother and birthdate of child:
individuals = individuals %&gt;%
    mutate(mother_birthdate = str_c(mother_pidlink, &quot;-&quot;,
          all_available_info_birth_date(ar08yr, ar08mth, ar08day))) # mother_pidlink-YYYY-MM; is NA if birth_year is missing

##Remove all with missing mother_birthdate
individuals = individuals %&gt;%
  filter(!is.na(mother_birthdate))


### Remove all families with multiple births:
## Mark multpile births
individuals = individuals %&gt;%
  mutate(multiple_birth = ifelse(duplicated(mother_birthdate), 1, 0))

## All women that ever had multiple births
twinmothers_individual = individuals %&gt;%
  filter(multiple_birth == 1)
length(unique(twinmothers_individual$mother_pidlink)) # number of families that have to be excluded due to multiple birth</code></pre>
<pre><code>## [1] 187</code></pre>
<pre class="r"><code>individuals = individuals %&gt;%
    filter(!(mother_pidlink %in% twinmothers_individual$mother_pidlink))</code></pre>
</div>
<div id="combine-informations-from-pregnancy-file-and-individual-file" class="section level2">
<h2>Combine informations from pregnancy file and individual file</h2>
<pre class="r"><code>## Combine informations from pregnancy history and individual files
alldata_pregnancy = inner_join(individuals, pregnancy, by = &quot;mother_birthdate&quot;)</code></pre>
</div>
<div id="gene-birthorder-based-on-both-parents" class="section level2">
<h2>Gene birthorder (based on both parents)</h2>
<pre class="r"><code>### Gene birthorder is calculated by grouping individuals together, for whom we know both parents and making a rank list
alldata_pregnancy = alldata_pregnancy %&gt;%
  group_by(mother_father_dyad) %&gt;%
    mutate(birthorder_genes = min_rank(birthdate),
           birthorder_genes = ifelse(is.na(mother_father_dyad), NA, birthorder_genes),
           siblingcount_genes = sum(!is.na(mother_father_dyad)))</code></pre>
</div>
<div id="select-iq-data" class="section level2">
<h2>Select IQ data</h2>
<pre class="r"><code>### IQ Informations
##ek2 (&gt;14yrs)
iq2.1 = ek_ek2 %&gt;% select(hhid14_9, pidlink, age, sex, ektype, resptype, result, reason, ek1_ans, ek2_ans, ek3_ans, ek4_ans, ek5_ans, ek6_ans, ek7_ans, ek8_ans, ek9_ans, ek10_ans, ek11_ans, ek12_ans, ek13_ans, ek14_ans, ek15_ans, ek16_ans, ek17_ans, ek18_ans, ek19_ans, ek20_ans, ek21_ans, ek22_ans)


##additional informations for adults: counting backwards
iq2.2 = b3b_co1 %&gt;% select(hhid14_9, pidlink, co04a, co04b, co04c, co04d, co04e, co07count, co10count)
##additional informations for adults: adaptive number test
iq2.3 = b3b_cob %&gt;% select(hhid14_9, pidlink, w_abil, cob18, cob19b)

## put all the informations for participants &gt;= 15 together
iq2 = full_join(iq2.1, iq2.2, by = &quot;pidlink&quot;)
iq2 = full_join(iq2, iq2.3, by = &quot;pidlink&quot;)
iq = iq2
iq &lt;- plyr::rename(iq, c(&quot;age&quot;=&quot;IQage&quot;)) 

### calculate iq scores
##Raven Test
answered_raven_items = iq %&gt;% select(ek1_ans:ek6_ans, ek11_ans, ek12_ans)
psych::alpha(data.frame(answered_raven_items))</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = data.frame(answered_raven_items))
## 
##   raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd
##       0.85      0.85    0.84      0.41 5.5 0.0012 0.53 0.33
## 
##  lower alpha upper     95% confidence boundaries
## 0.85 0.85 0.85 
## 
##  Reliability if an item is dropped:
##          raw_alpha std.alpha G6(smc) average_r S/N alpha se
## ek1_ans       0.82      0.82    0.81      0.39 4.5   0.0014
## ek2_ans       0.81      0.81    0.80      0.38 4.3   0.0015
## ek3_ans       0.81      0.81    0.80      0.38 4.3   0.0015
## ek4_ans       0.82      0.81    0.81      0.38 4.4   0.0014
## ek5_ans       0.83      0.83    0.83      0.41 4.9   0.0013
## ek6_ans       0.85      0.85    0.84      0.44 5.6   0.0012
## ek11_ans      0.83      0.82    0.82      0.40 4.6   0.0014
## ek12_ans      0.86      0.86    0.85      0.46 5.9   0.0011
## 
##  Item statistics 
##              n raw.r std.r r.cor r.drop mean   sd
## ek1_ans  36380  0.74  0.74  0.71   0.65 0.74 0.44
## ek2_ans  36380  0.80  0.80  0.79   0.72 0.67 0.47
## ek3_ans  36380  0.79  0.79  0.77   0.71 0.58 0.49
## ek4_ans  36380  0.78  0.77  0.74   0.69 0.59 0.49
## ek5_ans  36380  0.68  0.68  0.60   0.56 0.50 0.50
## ek6_ans  36380  0.54  0.55  0.44   0.40 0.28 0.45
## ek11_ans 36380  0.73  0.72  0.67   0.62 0.61 0.49
## ek12_ans 36380  0.47  0.49  0.36   0.34 0.22 0.42
## 
## Non missing response frequency for each item
##             0    1 miss
## ek1_ans  0.26 0.74    0
## ek2_ans  0.33 0.67    0
## ek3_ans  0.42 0.58    0
## ek4_ans  0.41 0.59    0
## ek5_ans  0.50 0.50    0
## ek6_ans  0.72 0.28    0
## ek11_ans 0.39 0.61    0
## ek12_ans 0.78 0.22    0</code></pre>
<pre class="r"><code>iq$raven = rowMeans( answered_raven_items, na.rm = T)
iq$raven[! iq$result %in% 1:2] = NA
qplot(iq$raven)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 5049 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/select%20IQ%20data-1.png" width="672" /></p>
<pre class="r"><code>##Math Test
answered_math_items = iq %&gt;% select(ek18_ans:ek22_ans)
psych::alpha(data.frame(answered_math_items))</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = data.frame(answered_math_items))
## 
##   raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd
##       0.68      0.68    0.64       0.3 2.1 0.0026 0.26 0.29
## 
##  lower alpha upper     95% confidence boundaries
## 0.68 0.68 0.69 
## 
##  Reliability if an item is dropped:
##          raw_alpha std.alpha G6(smc) average_r S/N alpha se
## ek18_ans      0.68      0.67    0.61      0.34 2.1   0.0027
## ek19_ans      0.60      0.60    0.54      0.28 1.5   0.0033
## ek20_ans      0.60      0.60    0.53      0.27 1.5   0.0034
## ek21_ans      0.66      0.65    0.60      0.32 1.9   0.0029
## ek22_ans      0.63      0.62    0.56      0.29 1.7   0.0032
## 
##  Item statistics 
##              n raw.r std.r r.cor r.drop mean   sd
## ek18_ans 36380  0.59  0.59  0.41   0.34 0.25 0.43
## ek19_ans 36380  0.71  0.71  0.61   0.50 0.28 0.45
## ek20_ans 36380  0.73  0.72  0.63   0.51 0.34 0.47
## ek21_ans 36380  0.60  0.63  0.46   0.38 0.18 0.38
## ek22_ans 36380  0.68  0.68  0.55   0.46 0.28 0.45
## 
## Non missing response frequency for each item
##             0    1 miss
## ek18_ans 0.75 0.25    0
## ek19_ans 0.72 0.28    0
## ek20_ans 0.66 0.34    0
## ek21_ans 0.82 0.18    0
## ek22_ans 0.72 0.28    0</code></pre>
<pre class="r"><code>iq$math = rowMeans( answered_math_items, na.rm = T)
iq$math[! iq$result %in% 1:2] = NA
qplot(iq$math)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 5049 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/select%20IQ%20data-2.png" width="672" /></p>
<pre class="r"><code>##Counting Items
# Create Right/Wrong Scores for the counting items
iq$co04aright = as.numeric(iq$co04a == 93)
iq$co04bright = as.numeric(iq$co04b == iq$co04a-7)
iq$co04cright = as.numeric(iq$co04c == iq$co04b-7)
iq$co04dright = as.numeric(iq$co04d == iq$co04c-7)
iq$co04eright = as.numeric(iq$co04e == iq$co04d-7)

answered_counting_items = iq %&gt;% select(co04aright:co04eright)
psych::alpha(data.frame(answered_counting_items))</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = data.frame(answered_counting_items))
## 
##   raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd
##       0.69      0.68    0.64      0.29 2.1 0.0024 0.73 0.29
## 
##  lower alpha upper     95% confidence boundaries
## 0.68 0.69 0.69 
## 
##  Reliability if an item is dropped:
##            raw_alpha std.alpha G6(smc) average_r S/N alpha se
## co04aright      0.71      0.71    0.65      0.38 2.4   0.0025
## co04bright      0.64      0.62    0.57      0.29 1.6   0.0028
## co04cright      0.60      0.59    0.54      0.27 1.5   0.0030
## co04dright      0.61      0.60    0.54      0.27 1.5   0.0030
## co04eright      0.60      0.59    0.54      0.27 1.5   0.0031
## 
##  Item statistics 
##                n raw.r std.r r.cor r.drop mean   sd
## co04aright 30452  0.43  0.51  0.27   0.23 0.95 0.22
## co04bright 29661  0.70  0.67  0.53   0.45 0.63 0.48
## co04cright 29260  0.73  0.71  0.61   0.52 0.69 0.46
## co04dright 29078  0.73  0.71  0.61   0.51 0.69 0.46
## co04eright 28983  0.73  0.71  0.61   0.52 0.70 0.46
## 
## Non missing response frequency for each item
##               0    1 miss
## co04aright 0.05 0.95 0.16
## co04bright 0.37 0.63 0.18
## co04cright 0.31 0.69 0.20
## co04dright 0.31 0.69 0.20
## co04eright 0.30 0.70 0.20</code></pre>
<pre class="r"><code>iq$count_backwards = rowSums( answered_counting_items, na.rm = T) / 5
qplot(iq$count_backwards)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="1_data_import_files/figure-html/select%20IQ%20data-3.png" width="672" /></p>
<pre class="r"><code>## Word Memory
iq$words_immediate = iq$co07count
iq$words_delayed = iq$co10count
qplot(iq$words_immediate, iq$words_delayed, geom = &quot;jitter&quot;)</code></pre>
<pre><code>## Warning: Removed 4917 rows containing missing values (geom_point).</code></pre>
<p><img src="1_data_import_files/figure-html/select%20IQ%20data-4.png" width="672" /></p>
<pre class="r"><code>answered_word_items = iq %&gt;% select(co07count,co10count)
psych::alpha(data.frame(answered_word_items))</code></pre>
<pre><code>## Warning in matrix(unlist(drop.item), ncol = 8, byrow = TRUE): data length
## [12] is not a sub-multiple or multiple of the number of columns [8]</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = data.frame(answered_word_items))
## 
##   raw_alpha std.alpha G6(smc) average_r S/N    ase mean  sd
##       0.87      0.87    0.77      0.77 6.8 0.0014  4.6 1.8
## 
##  lower alpha upper     95% confidence boundaries
## 0.87 0.87 0.87 
## 
##  Reliability if an item is dropped:
##           raw_alpha std.alpha G6(smc) average_r  S/N alpha se
## co07count      0.77      0.77     0.6      0.77   NA       NA
## co10count      0.60      0.77      NA        NA 0.77   0.0046
## 
##  Item statistics 
##               n raw.r std.r r.cor r.drop mean  sd
## co07count 31471  0.94  0.94  0.83   0.77  5.1 1.8
## co10count 31471  0.94  0.94  0.83   0.77  4.2 1.9</code></pre>
<pre class="r"><code>iq$words_remembered_avg = rowMeans( answered_word_items, na.rm = T)
qplot(iq$words_remembered_avg)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 4917 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/select%20IQ%20data-5.png" width="672" /></p>
<pre class="r"><code>##Adaptive Numbering
iq$adaptive_numbering = iq$w_abil


#iq$drew_pentagons = as.numeric(iq$cob19b == 1)
#iq$number_of_animals = iq$cob18

## Correlation of all Iq-Tests
round(cor(iq %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering), use = &quot;pairwise.complete.obs&quot;), 2)</code></pre>
<pre><code>##                    raven math count_backwards words_immediate
## raven               1.00 0.41            0.32            0.38
## math                0.41 1.00            0.26            0.31
## count_backwards     0.32 0.26            1.00            0.33
## words_immediate     0.38 0.31            0.33            1.00
## words_delayed       0.37 0.31            0.30            0.77
## adaptive_numbering  0.45 0.35            0.40            0.40
##                    words_delayed adaptive_numbering
## raven                       0.37               0.45
## math                        0.31               0.35
## count_backwards             0.30               0.40
## words_immediate             0.77               0.40
## words_delayed               1.00               0.37
## adaptive_numbering          0.37               1.00</code></pre>
<pre class="r"><code>##Missingness_Patterns
formr::missingness_patterns(iq %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering))</code></pre>
<pre><code>##  index                col missings
##      1              raven     5049
##      2               math     5049
##      3 adaptive_numbering     4979
##      4    words_immediate     4917
##      5      words_delayed     4917</code></pre>
<pre><code>##     Pattern  Freq            Culprit
## 1 _________ 31000                  _
## 2 1_2_3_4_5  4593                   
## 3 1_2______   409                   
## 4 ____3_4_5   324                   
## 5 1_2_3____    47                   
## 6 ____3____    15 adaptive_numbering</code></pre>
</div>
<div id="compute-g-factor" class="section level2">
<h2>compute g factor</h2>
<pre class="r"><code>library(psych)</code></pre>
<pre><code>## 
## Attaching package: &#39;psych&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:ggplot2&#39;:
## 
##     %+%, alpha</code></pre>
<pre class="r"><code>fa.parallel(iq %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering) %&gt;% data.frame())</code></pre>
<p><img src="1_data_import_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre><code>## Parallel analysis suggests that the number of factors =  2  and the number of components =  1</code></pre>
<pre class="r"><code>fa(iq %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering) %&gt;% data.frame())</code></pre>
<pre><code>## Factor Analysis using method =  minres
## Call: fa(r = iq %&gt;% select(raven, math, count_backwards, words_immediate, 
##     words_delayed, adaptive_numbering) %&gt;% data.frame())
## Standardized loadings (pattern matrix) based upon correlation matrix
##                     MR1   h2   u2 com
## raven              0.55 0.30 0.70   1
## math               0.45 0.21 0.79   1
## count_backwards    0.46 0.21 0.79   1
## words_immediate    0.81 0.66 0.34   1
## words_delayed      0.80 0.64 0.36   1
## adaptive_numbering 0.56 0.31 0.69   1
## 
##                 MR1
## SS loadings    2.33
## Proportion Var 0.39
## 
## Mean item complexity =  1
## Test of the hypothesis that 1 factor is sufficient.
## 
## The degrees of freedom for the null model are  15  and the objective function was  1.88 with Chi Square of  68233.51
## The degrees of freedom for the model are 9  and the objective function was  0.32 
## 
## The root mean square of the residuals (RMSR) is  0.09 
## The df corrected root mean square of the residuals is  0.12 
## 
## The harmonic number of observations is  31392 with the empirical chi square  7933.27  with prob &lt;  0 
## The total number of observations was  36388  with MLE Chi Square =  11667.14  with prob &lt;  0 
## 
## Tucker Lewis Index of factoring reliability =  0.715
## RMSEA index =  0.189  and the 90 % confidence intervals are  0.186 0.192
## BIC =  11572.62
## Fit based upon off diagonal values = 0.95
## Measures of factor score adequacy             
##                                                 MR1
## Correlation of scores with factors             0.91
## Multiple R square of scores with factors       0.83
## Minimum correlation of possible factor scores  0.65</code></pre>
<pre class="r"><code>omega(iq %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering) %&gt;% data.frame())</code></pre>
<p><img src="1_data_import_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
<pre><code>## Omega 
## Call: omega(m = iq %&gt;% select(raven, math, count_backwards, words_immediate, 
##     words_delayed, adaptive_numbering) %&gt;% data.frame())
## Alpha:                 0.79 
## G.6:                   0.79 
## Omega Hierarchical:    0.68 
## Omega H asymptotic:    0.81 
## Omega Total            0.85 
## 
## Schmid Leiman Factor loadings greater than  0.2 
##                       g   F1*   F2*   F3*   h2   u2   p2
## raven              0.65        0.39       0.57 0.43 0.73
## math               0.49        0.22       0.30 0.70 0.82
## count_backwards    0.51              0.28 0.34 0.66 0.77
## words_immediate    0.58  0.54             0.63 0.37 0.53
## words_delayed      0.57  0.82             1.00 0.00 0.33
## adaptive_numbering 0.65              0.27 0.50 0.50 0.85
## 
## With eigenvalues of:
##    g  F1*  F2*  F3* 
## 2.01 0.96 0.21 0.16 
## 
## general/max  2.09   max/min =   6.2
## mean percent general =  0.67    with sd =  0.2 and cv of  0.3 
## Explained Common Variance of the general factor =  0.6 
## 
## The degrees of freedom are 0  and the fit is  0 
## The number of observations was  36388  with Chi Square =  0.6  with prob &lt;  NA
## The root mean square of the residuals is  0 
## The df corrected root mean square of the residuals is  NA
## 
## Compare this with the adequacy of just a general factor and no group factors
## The degrees of freedom for just the general factor are 9  and the fit is  0.53 
## The number of observations was  36388  with Chi Square =  19293.51  with prob &lt;  0
## The root mean square of the residuals is  0.12 
## The df corrected root mean square of the residuals is  0.15 
## 
## RMSEA index =  0.243  and the 90 % confidence intervals are  0.24 0.246
## BIC =  19199 
## 
## Measures of factor score adequacy             
##                                                  g  F1*   F2*   F3*
## Correlation of scores with factors            0.84 0.92  0.46  0.40
## Multiple R square of scores with factors      0.70 0.84  0.21  0.16
## Minimum correlation of factor score estimates 0.41 0.69 -0.57 -0.69
## 
##  Total, General and Subset omega for each subset
##                                                  g  F1*  F2*  F3*
## Omega total for total scores and subscales    0.85 0.89 0.60 0.59
## Omega general for total scores and subscales  0.68 0.37 0.46 0.48
## Omega group for total scores and subscales    0.14 0.52 0.13 0.11</code></pre>
<pre class="r"><code>library(lavaan)</code></pre>
<pre><code>## This is lavaan 0.5-22</code></pre>
<pre><code>## lavaan is BETA software! Please report any bugs.</code></pre>
<pre class="r"><code>iq$adaptive_numbering = iq$adaptive_numbering/100
&quot;g_factor =~ raven + math + count_backwards +  words_delayed+ adaptive_numbering&quot; %&gt;%
  cfa(missing = &quot;fiml&quot;, data = iq) -&gt; cfa_g
summary(cfa_g)</code></pre>
<pre><code>## lavaan (0.5-22) converged normally after  46 iterations
## 
##   Number of observations                         36388
## 
##   Number of missing patterns                         6
## 
##   Estimator                                         ML
##   Minimum Function Test Statistic              472.825
##   Degrees of freedom                                 5
##   P-value (Chi-square)                           0.000
## 
## Parameter Estimates:
## 
##   Information                                 Observed
##   Standard Errors                             Standard
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   g_factor =~                                         
##     raven             1.000                           
##     math              0.890    0.012   76.744    0.000
##     count_backwrds    1.181    0.015   79.028    0.000
##     words_delayed     5.854    0.077   75.827    0.000
##     adaptiv_nmbrng    2.708    0.032   84.413    0.000
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .raven             0.582    0.002  368.756    0.000
##    .math              0.282    0.002  166.076    0.000
##    .count_backwrds    0.595    0.002  297.752    0.000
##    .words_delayed     4.005    0.011  363.733    0.000
##    .adaptiv_nmbrng    5.013    0.004 1192.667    0.000
##     g_factor          0.000                           
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .raven             0.040    0.000   88.200    0.000
##    .math              0.060    0.001  105.879    0.000
##    .count_backwrds    0.095    0.001   98.166    0.000
##    .words_delayed     2.466    0.023  105.411    0.000
##    .adaptiv_nmbrng    0.271    0.003   85.260    0.000
##     g_factor          0.036    0.001   55.493    0.000</code></pre>
<pre class="r"><code>iq$g_factor = predict(cfa_g)[,1]
qplot(iq$g_factor)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 5388 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/unnamed-chunk-2-3.png" width="672" /></p>
<pre class="r"><code>round(cor(iq %&gt;% select(g_factor, raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering), use = &quot;pairwise.complete.obs&quot;), 2)</code></pre>
<pre><code>##                    g_factor raven math count_backwards words_immediate
## g_factor               1.00  0.77 0.63            0.60            0.61
## raven                  0.77  1.00 0.41            0.32            0.38
## math                   0.63  0.41 1.00            0.26            0.31
## count_backwards        0.60  0.32 0.26            1.00            0.33
## words_immediate        0.61  0.38 0.31            0.33            1.00
## words_delayed          0.64  0.37 0.31            0.30            0.77
## adaptive_numbering     0.79  0.45 0.35            0.40            0.40
##                    words_delayed adaptive_numbering
## g_factor                    0.64               0.79
## raven                       0.37               0.45
## math                        0.31               0.35
## count_backwards             0.30               0.40
## words_immediate             0.77               0.40
## words_delayed               1.00               0.37
## adaptive_numbering          0.37               1.00</code></pre>
<pre class="r"><code>formr::missingness_patterns(iq %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering, g_factor)) ## oops, lavaan only predicts the g factor for complete cases</code></pre>
<pre><code>##  index                col missings
##      1           g_factor     5388
##      2              raven     5049
##      3               math     5049
##      4 adaptive_numbering     4979
##      5    words_immediate     4917
##      6      words_delayed     4917</code></pre>
<pre><code>##       Pattern  Freq Culprit
## 1 ___________ 31000       _
## 2 1_2_3_4_5_6  4593        
## 3 1_2_3______   409        
## 4 1_____4_5_6   324        
## 5 1_2_3_4____    47        
## 6 1_____4____    15</code></pre>
<pre class="r"><code># impute missing values
# library(missMDA)
# estimate number of components
# rr = iq %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering)
# nb &lt;- estim_ncpPCA(rr, ncp.min=0, ncp.max=5)
# actual impute
# rr.impute &lt;- imputePCA(rr, ncp=nb$ncp)
# https://stats.stackexchange.com/questions/123725/how-can-i-estimate-a-principal-component-from-incomplete-data?noredirect=1&amp;lq=1

# Run pca
# pca.fit &lt;- prcomp(rr.impute$completeObs)
# pca.fit$rotation</code></pre>
</div>
<div id="select-personality-data" class="section level2">
<h2>Select personality data</h2>
<pre class="r"><code>### Personality
##Rearrange personality data so that every individual has only one row
pers = spread(b3b_psn, psntype, psn01)
##name columns
colnames(pers) &lt;- c(&quot;hhid14_9&quot;, &quot;pid14&quot;, &quot;hhid14&quot;, &quot;pidlink&quot;, &quot;version&quot;, &quot;module&quot;, &quot;e1&quot;, &quot;c1&quot;, &quot;o1&quot;, &quot;e2r&quot;, &quot;n1r&quot;, &quot;a1&quot;, &quot;n2r&quot;, &quot;o2&quot;, &quot;c2r&quot;, &quot;o3&quot;, &quot;a2&quot;, &quot;c3&quot;, &quot;e3&quot;, &quot;a3r&quot;, &quot;n3&quot;)
pers = pers %&gt;% select(hhid14_9, pidlink, e1, c1, o1, e2r, n1r, a1, n2r, o2, c2r, o3, a2, c3, e3, a3r, n3)

##Extraversion
pers$e2r_reversed = 6 - pers$e2r
extraversion = pers %&gt;% select(e1, e2r_reversed, e3)
psych::alpha(data.frame(extraversion), check.keys = T)</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = data.frame(extraversion), check.keys = T)
## 
##   raw_alpha std.alpha G6(smc) average_r  S/N    ase mean   sd
##       0.37      0.35    0.28      0.15 0.54 0.0056  3.4 0.67
## 
##  lower alpha upper     95% confidence boundaries
## 0.36 0.37 0.38 
## 
##  Reliability if an item is dropped:
##              raw_alpha std.alpha G6(smc) average_r   S/N alpha se
## e1               0.072     0.081   0.042     0.042 0.088   0.0092
## e2r_reversed     0.218     0.246   0.140     0.140 0.326   0.0077
## e3               0.429     0.429   0.273     0.273 0.753   0.0064
## 
##  Item statistics 
##                  n raw.r std.r r.cor r.drop mean   sd
## e1           31446  0.77  0.71  0.48   0.30  3.1 1.14
## e2r_reversed 31446  0.73  0.67  0.37   0.24  3.0 1.12
## e3           31446  0.44  0.60  0.19   0.11  4.2 0.67
## 
## Non missing response frequency for each item
##                 1    2    3    4    5 miss
## e1           0.03 0.39 0.08 0.39 0.11    0
## e2r_reversed 0.07 0.36 0.09 0.43 0.05    0
## e3           0.00 0.03 0.05 0.64 0.28    0</code></pre>
<pre class="r"><code>pers$big5_ext = rowMeans(extraversion)
qplot(pers$big5_ext)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="1_data_import_files/figure-html/select%20pesonality%20data-1.png" width="672" /></p>
<pre class="r"><code>##conscientiousness
pers$c2r_reversed = 6 - pers$c2r
conscientiousness = pers %&gt;% select(c1, c2r_reversed, c3)
psych::alpha(data.frame(conscientiousness), check.keys = T)</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = data.frame(conscientiousness), check.keys = T)
## 
##   raw_alpha std.alpha G6(smc) average_r  S/N   ase mean   sd
##       0.29      0.31    0.24      0.13 0.45 0.007  3.8 0.55
## 
##  lower alpha upper     95% confidence boundaries
## 0.27 0.29 0.3 
## 
##  Reliability if an item is dropped:
##              raw_alpha std.alpha G6(smc) average_r  S/N alpha se
## c1                0.10      0.10   0.054     0.054 0.11   0.0101
## c2r_reversed      0.35      0.36   0.219     0.219 0.56   0.0071
## c3                0.20      0.21   0.116     0.116 0.26   0.0087
## 
##  Item statistics 
##                  n raw.r std.r r.cor r.drop mean   sd
## c1           31446  0.61  0.69  0.42   0.23  4.1 0.71
## c2r_reversed 31446  0.65  0.60  0.19   0.10  3.6 0.95
## c3           31446  0.67  0.65  0.34   0.17  3.8 0.90
## 
## Non missing response frequency for each item
##                 1    2    3    4    5 miss
## c1           0.01 0.04 0.04 0.66 0.25    0
## c2r_reversed 0.03 0.18 0.07 0.65 0.07    0
## c3           0.01 0.12 0.08 0.63 0.15    0</code></pre>
<pre class="r"><code>pers$big5_con = rowMeans(conscientiousness)
qplot(pers$big5_con)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="1_data_import_files/figure-html/select%20pesonality%20data-2.png" width="672" /></p>
<pre class="r"><code>##Openness
openness = pers %&gt;% select(o1, o2, o3)
psych::alpha(data.frame(openness), check.keys = T)</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = data.frame(openness), check.keys = T)
## 
##   raw_alpha std.alpha G6(smc) average_r  S/N    ase mean   sd
##       0.45      0.45    0.35      0.21 0.81 0.0054  3.7 0.67
## 
##  lower alpha upper     95% confidence boundaries
## 0.43 0.45 0.46 
## 
##  Reliability if an item is dropped:
##    raw_alpha std.alpha G6(smc) average_r  S/N alpha se
## o1      0.30      0.30    0.18      0.18 0.43   0.0078
## o2      0.39      0.39    0.25      0.25 0.65   0.0068
## o3      0.35      0.36    0.22      0.22 0.55   0.0073
## 
##  Item statistics 
##        n raw.r std.r r.cor r.drop mean   sd
## o1 31446  0.71  0.71  0.45   0.30  3.7 0.98
## o2 31446  0.70  0.67  0.37   0.25  3.5 1.05
## o3 31446  0.65  0.69  0.41   0.27  4.0 0.88
## 
## Non missing response frequency for each item
##       1    2    3    4    5 miss
## o1 0.02 0.18 0.08 0.58 0.14    0
## o2 0.03 0.22 0.09 0.54 0.12    0
## o3 0.01 0.10 0.05 0.61 0.23    0</code></pre>
<pre class="r"><code>pers$big5_open = rowMeans(openness)
qplot(pers$big5_open)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="1_data_import_files/figure-html/select%20pesonality%20data-3.png" width="672" /></p>
<pre class="r"><code>## Neuroticism
pers$n1r_reversed = 6 - pers$n1r
pers$n2r_reversed = 6 - pers$n2r
neuroticism = pers %&gt;% select(n1r_reversed, n2r_reversed, n3)
pers$big5_neu = rowMeans(neuroticism)
qplot(pers$big5_neu)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="1_data_import_files/figure-html/select%20pesonality%20data-4.png" width="672" /></p>
<pre class="r"><code>##Agreeableness
pers$a3r_reversed = 6- pers$a3r
agreeableness= pers %&gt;% select(a1, a2, a3r_reversed)
pers$big5_agree = rowMeans(agreeableness)
qplot(pers$big5_agree)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="1_data_import_files/figure-html/select%20pesonality%20data-5.png" width="672" /></p>
</div>
<div id="select-risk-taking-data" class="section level2">
<h2>Select risk taking data</h2>
<pre class="r"><code>###Risktaking
risk = b3a_si %&gt;% select(hhid14_9, pidlink, random_si, si01, si02, si03, si04, si05, si11, si12, si13, si14, si15)

## 8 means they didnt know which answer they would choose
risk$si01[ risk$si01 == 8] = NA
risk$si02[ risk$si02 == 8] = NA
risk$si03[ risk$si03 == 8] = NA
risk$si04[ risk$si04 == 8] = NA
risk$si05[ risk$si05 == 8] = NA
risk$si11[ risk$si11 == 8] = NA
risk$si12[ risk$si12 == 8] = NA
risk$si13[ risk$si13 == 8] = NA
risk$si14[ risk$si14 == 8] = NA
risk$si15[ risk$si15 == 8] = NA

## calculate a risk score for risk game A 
# (5 = gamble averse, Ordinalskala : 1 = risk loving, 4 = risk averse)
risk$riskA = ifelse(risk$si01 == 1 &amp; risk$si02 == 1, 5,
             ifelse(risk$si01 == 2 &amp; risk$si03 == 1 &amp; risk$si04 == 1, 4,
             ifelse(risk$si01 == 2 &amp; risk$si03 == 1 &amp; risk$si04 == 2, 3,
             ifelse(risk$si01 == 2 &amp; risk$si03 == 2 &amp; risk$si05 == 1, 2,
             ifelse(risk$si01 == 2 &amp; risk$si03 == 2 &amp; risk$si05 == 2, 1,
             NA)))))
qplot(risk$riskA[risk$riskA != 5])</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 3882 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/select%20risk%20taking%20data-1.png" width="672" /></p>
<pre class="r"><code>## calculate a risk score for risk game B 
# (5 = gamble averse, Ordinalskala : 1 = risk loving, 4 = risk averse)
risk$riskB = ifelse(risk$si11 == 2 &amp; risk$si12 == 1, 5,
             ifelse(risk$si11 == 1 &amp; risk$si13 == 1 &amp; risk$si14 == 1, 4,
             ifelse(risk$si11 == 1 &amp; risk$si13 == 1 &amp; risk$si14 == 2, 3,
             ifelse(risk$si11 == 1 &amp; risk$si13 == 2 &amp; risk$si15 == 1, 2,
             ifelse(risk$si11 == 1 &amp; risk$si13 == 2 &amp; risk$si15 == 2, 1,
             NA)))))
qplot(risk$riskB[risk$riskB !=5])</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 2084 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/select%20risk%20taking%20data-2.png" width="672" /></p>
<pre class="r"><code>psych::alpha(data.frame(risk %&gt;% select(riskA, riskB)), check.keys = T)</code></pre>
<pre><code>## Warning in matrix(unlist(drop.item), ncol = 8, byrow = TRUE): data length
## [12] is not a sub-multiple or multiple of the number of columns [8]</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = data.frame(risk %&gt;% select(riskA, riskB)), check.keys = T)
## 
##   raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd
##       0.29      0.33     0.2       0.2 0.5 0.0067  3.6 0.96
## 
##  lower alpha upper     95% confidence boundaries
## 0.28 0.29 0.3 
## 
##  Reliability if an item is dropped:
##       raw_alpha std.alpha G6(smc) average_r S/N alpha se
## riskA      0.20       0.2    0.04       0.2  NA       NA
## riskB      0.04       0.2      NA        NA 0.2   0.0025
## 
##  Item statistics 
##           n raw.r std.r r.cor r.drop mean   sd
## riskA 27780  0.90  0.77  0.35    0.2  3.4 1.51
## riskB 29578  0.64  0.77  0.35    0.2  3.9 0.82
## 
## Non missing response frequency for each item
##          1    2    3    4    5 miss
## riskA 0.19 0.12 0.11 0.24 0.33 0.12
## riskB 0.04 0.02 0.11 0.70 0.13 0.07</code></pre>
</div>
<div id="merge-data" class="section level2">
<h2>Merge data</h2>
<pre class="r"><code>### Merge all data for people with birthorder informations
alldata_birthorder = left_join(alldata_pregnancy, iq, by = &quot;pidlink&quot;)
alldata_birthorder = left_join(alldata_birthorder, pers, by = &quot;pidlink&quot;)
alldata_birthorder = left_join(alldata_birthorder, risk, by = &quot;pidlink&quot;)

alldata = left_join(individuals_unchanged, iq, by = &quot;pidlink&quot;)
alldata = left_join(alldata, pers, by = &quot;pidlink&quot;)
alldata = left_join(alldata, risk, by = &quot;pidlink&quot;)</code></pre>
</div>
<div id="exploring-data" class="section level2">
<h2>Exploring data</h2>
<pre class="r"><code>### Personality
ggplot(alldata, aes(x=big5_agree, y=big5_neu)) + geom_jitter()</code></pre>
<pre><code>## Warning: Removed 44234 rows containing missing values (geom_point).</code></pre>
<p><img src="1_data_import_files/figure-html/exploring%20data-1.png" width="672" /></p>
<pre class="r"><code>###Openness and Intelligence
round(cor(alldata %&gt;% ungroup %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering, g_factor, big5_open), use = &quot;pairwise.complete.obs&quot;), 2)</code></pre>
<pre><code>##                    raven math count_backwards words_immediate
## raven               1.00 0.41            0.32            0.38
## math                0.41 1.00            0.26            0.31
## count_backwards     0.32 0.26            1.00            0.33
## words_immediate     0.38 0.31            0.33            1.00
## words_delayed       0.37 0.31            0.30            0.77
## adaptive_numbering  0.45 0.35            0.40            0.40
## g_factor            0.77 0.63            0.60            0.61
## big5_open           0.15 0.13            0.12            0.17
##                    words_delayed adaptive_numbering g_factor big5_open
## raven                       0.37               0.45     0.77      0.15
## math                        0.31               0.35     0.63      0.13
## count_backwards             0.30               0.40     0.60      0.12
## words_immediate             0.77               0.40     0.61      0.17
## words_delayed               1.00               0.37     0.64      0.15
## adaptive_numbering          0.37               1.00     0.79      0.16
## g_factor                    0.64               0.79     1.00      0.20
## big5_open                   0.15               0.16     0.20      1.00</code></pre>
<pre class="r"><code>###Other personality factors and Intelligence
round(cor(alldata %&gt;% ungroup %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering, g_factor, big5_con), use = &quot;pairwise.complete.obs&quot;), 2)</code></pre>
<pre><code>##                    raven  math count_backwards words_immediate
## raven               1.00  0.41            0.32            0.38
## math                0.41  1.00            0.26            0.31
## count_backwards     0.32  0.26            1.00            0.33
## words_immediate     0.38  0.31            0.33            1.00
## words_delayed       0.37  0.31            0.30            0.77
## adaptive_numbering  0.45  0.35            0.40            0.40
## g_factor            0.77  0.63            0.60            0.61
## big5_con            0.00 -0.01            0.03            0.03
##                    words_delayed adaptive_numbering g_factor big5_con
## raven                       0.37               0.45     0.77     0.00
## math                        0.31               0.35     0.63    -0.01
## count_backwards             0.30               0.40     0.60     0.03
## words_immediate             0.77               0.40     0.61     0.03
## words_delayed               1.00               0.37     0.64     0.01
## adaptive_numbering          0.37               1.00     0.79     0.02
## g_factor                    0.64               0.79     1.00     0.02
## big5_con                    0.01               0.02     0.02     1.00</code></pre>
<pre class="r"><code>round(cor(alldata %&gt;% ungroup %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering, g_factor, big5_ext), use = &quot;pairwise.complete.obs&quot;), 2)</code></pre>
<pre><code>##                    raven math count_backwards words_immediate
## raven               1.00 0.41            0.32            0.38
## math                0.41 1.00            0.26            0.31
## count_backwards     0.32 0.26            1.00            0.33
## words_immediate     0.38 0.31            0.33            1.00
## words_delayed       0.37 0.31            0.30            0.77
## adaptive_numbering  0.45 0.35            0.40            0.40
## g_factor            0.77 0.63            0.60            0.61
## big5_ext            0.07 0.06            0.08            0.09
##                    words_delayed adaptive_numbering g_factor big5_ext
## raven                       0.37               0.45     0.77     0.07
## math                        0.31               0.35     0.63     0.06
## count_backwards             0.30               0.40     0.60     0.08
## words_immediate             0.77               0.40     0.61     0.09
## words_delayed               1.00               0.37     0.64     0.08
## adaptive_numbering          0.37               1.00     0.79     0.08
## g_factor                    0.64               0.79     1.00     0.11
## big5_ext                    0.08               0.08     0.11     1.00</code></pre>
<pre class="r"><code>round(cor(alldata %&gt;% ungroup %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering, g_factor, big5_agree), use = &quot;pairwise.complete.obs&quot;), 2)</code></pre>
<pre><code>##                    raven  math count_backwards words_immediate
## raven               1.00  0.41            0.32            0.38
## math                0.41  1.00            0.26            0.31
## count_backwards     0.32  0.26            1.00            0.33
## words_immediate     0.38  0.31            0.33            1.00
## words_delayed       0.37  0.31            0.30            0.77
## adaptive_numbering  0.45  0.35            0.40            0.40
## g_factor            0.77  0.63            0.60            0.61
## big5_agree         -0.03 -0.02            0.01            0.01
##                    words_delayed adaptive_numbering g_factor big5_agree
## raven                       0.37               0.45     0.77      -0.03
## math                        0.31               0.35     0.63      -0.02
## count_backwards             0.30               0.40     0.60       0.01
## words_immediate             0.77               0.40     0.61       0.01
## words_delayed               1.00               0.37     0.64      -0.01
## adaptive_numbering          0.37               1.00     0.79      -0.01
## g_factor                    0.64               0.79     1.00      -0.02
## big5_agree                 -0.01              -0.01    -0.02       1.00</code></pre>
<pre class="r"><code>round(cor(alldata %&gt;% ungroup %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering, g_factor, big5_neu), use = &quot;pairwise.complete.obs&quot;), 2)</code></pre>
<pre><code>##                    raven math count_backwards words_immediate
## raven               1.00 0.41            0.32            0.38
## math                0.41 1.00            0.26            0.31
## count_backwards     0.32 0.26            1.00            0.33
## words_immediate     0.38 0.31            0.33            1.00
## words_delayed       0.37 0.31            0.30            0.77
## adaptive_numbering  0.45 0.35            0.40            0.40
## g_factor            0.77 0.63            0.60            0.61
## big5_neu            0.01 0.02           -0.01           -0.02
##                    words_delayed adaptive_numbering g_factor big5_neu
## raven                       0.37               0.45     0.77     0.01
## math                        0.31               0.35     0.63     0.02
## count_backwards             0.30               0.40     0.60    -0.01
## words_immediate             0.77               0.40     0.61    -0.02
## words_delayed               1.00               0.37     0.64     0.00
## adaptive_numbering          0.37               1.00     0.79     0.00
## g_factor                    0.64               0.79     1.00     0.01
## big5_neu                    0.00               0.00     0.01     1.00</code></pre>
<pre class="r"><code># Opennes has the highest values!
ggplot(alldata, aes(x=big5_open, y=g_factor)) + geom_jitter() + geom_smooth(method=lm) </code></pre>
<pre><code>## Warning: Removed 44680 rows containing non-finite values (stat_smooth).</code></pre>
<pre><code>## Warning: Removed 44680 rows containing missing values (geom_point).</code></pre>
<p><img src="1_data_import_files/figure-html/exploring%20data-2.png" width="672" /></p>
<pre class="r"><code>### Birth Order
alldata_birthorder %&gt;%
  filter(birthorder_uterus_alive&lt;6) %&gt;%
  ggplot(aes(x=birthorder_uterus_alive, y=g_factor)) + geom_jitter() + geom_smooth(method=lm) </code></pre>
<pre><code>## Warning: Removed 11901 rows containing non-finite values (stat_smooth).</code></pre>
<pre><code>## Warning: Removed 11901 rows containing missing values (geom_point).</code></pre>
<p><img src="1_data_import_files/figure-html/exploring%20data-3.png" width="672" /></p>
<pre class="r"><code>table(alldata_birthorder$sibling_count_uterus_alive)</code></pre>
<pre><code>## 
##    1    2    3    4    5    6    7    8    9   10   11   12   13   14 
## 3232 5876 3429 1936 1043  639  311  212  112   98   36   39    5   16</code></pre>
<pre class="r"><code>alldata_birthorder %&gt;%
  filter(birthorder_uterus_alive&lt;8) %&gt;%
  filter(sibling_count_uterus_alive&lt;8) %&gt;%
  ggplot(aes(x=birthorder_uterus_alive, y=g_factor)) + 
  facet_wrap(~ sibling_count_uterus_alive) + 
  geom_jitter() + geom_smooth(method=lm) </code></pre>
<pre><code>## Warning: Removed 11996 rows containing non-finite values (stat_smooth).</code></pre>
<pre><code>## Warning: Removed 11996 rows containing missing values (geom_point).</code></pre>
<p><img src="1_data_import_files/figure-html/exploring%20data-4.png" width="672" /></p>
<pre class="r"><code>alldata_birthorder %&gt;% select(birthorder_uterus_alive, sibling_count_uterus_alive, birthdate) -&gt; subs</code></pre>
<pre><code>## Adding missing grouping variables: `mother_father_dyad`</code></pre>
<pre class="r"><code>alldata_birthorder$byear = as.numeric(stringr::str_sub(alldata_birthorder$birthdate,1,4))

alldata_birthorder %&gt;%
  filter(birthorder_uterus_alive &lt; 8) %&gt;%
  filter(sibling_count_uterus_alive &lt; 8) %&gt;%
   mutate(birthorder_uterus_alive = factor(birthorder_uterus_alive),
         sibling_count_uters_alive = sibling_count_uterus_alive) %&gt;%
  ggplot(aes(x=birthorder_uterus_alive, y=g_factor, colour = sibling_count_uterus_alive, group = sibling_count_uterus_alive)) + 
  geom_pointrange(fun.data = &quot;mean_cl_boot&quot;, stat = &quot;summary&quot;, position = position_dodge(width = 0.4)) + 
  geom_line(fun.data = &quot;mean_cl_boot&quot;, stat = &quot;summary&quot;, position = position_dodge(width = 0.4))</code></pre>
<pre><code>## Warning: Removed 11996 rows containing non-finite values (stat_summary).</code></pre>
<pre><code>## Warning: Removed 11996 rows containing non-finite values (stat_summary).</code></pre>
<p><img src="1_data_import_files/figure-html/exploring%20data-5.png" width="672" /></p>
<pre class="r"><code>alldata_birthorder %&gt;%
  filter(birthorder_uterus_alive &lt; 8) %&gt;%
  filter(sibling_count_uterus_alive &lt; 8) %&gt;%
   mutate(birthorder_uterus_alive = factor(birthorder_uterus_alive),
         sibling_count_uters_alive = sibling_count_uterus_alive) %&gt;%
  ggplot(aes(x=birthorder_uterus_alive, y=big5_open, colour = sibling_count_uterus_alive, group = sibling_count_uterus_alive)) + 
  geom_pointrange(fun.data = &quot;mean_cl_boot&quot;, stat = &quot;summary&quot;, position = position_dodge(width = 0.4)) + 
  geom_line(fun.data = &quot;mean_cl_boot&quot;, stat = &quot;summary&quot;, position = position_dodge(width = 0.4))</code></pre>
<pre><code>## Warning: Removed 11966 rows containing non-finite values (stat_summary).</code></pre>
<pre><code>## Warning: Removed 11966 rows containing non-finite values (stat_summary).</code></pre>
<p><img src="1_data_import_files/figure-html/exploring%20data-6.png" width="672" /></p>
<pre class="r"><code>alldata_birthorder %&gt;%
  filter(birthorder_uterus_alive &lt; 8) %&gt;%
  filter(sibling_count_uterus_alive &lt; 8) %&gt;%
   mutate(birthorder_uterus_alive = factor(birthorder_uterus_alive),
         sibling_count_uters_alive = sibling_count_uterus_alive) %&gt;%
  ggplot(aes(x=birthorder_uterus_alive, y=big5_ext, colour = sibling_count_uterus_alive, group = sibling_count_uterus_alive)) + 
  geom_pointrange(fun.data = &quot;mean_cl_boot&quot;, stat = &quot;summary&quot;, position = position_dodge(width = 0.4)) + 
  geom_line(fun.data = &quot;mean_cl_boot&quot;, stat = &quot;summary&quot;, position = position_dodge(width = 0.4))</code></pre>
<pre><code>## Warning: Removed 11966 rows containing non-finite values (stat_summary).

## Warning: Removed 11966 rows containing non-finite values (stat_summary).</code></pre>
<p><img src="1_data_import_files/figure-html/exploring%20data-7.png" width="672" /></p>
</div>
<div id="save-data" class="section level2">
<h2>Save data</h2>
<p>for future analyses</p>
<pre class="r"><code>saveRDS(alldata_birthorder, file = &quot;data/alldata_birthorder.rds&quot;)

saveRDS(alldata, file = &quot;data/alldata.rds&quot;)</code></pre>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
