<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Laura Botzet" />


<title></title>

<script src="library/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="library/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="library/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="library/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="library/bootstrap-3.3.5/shim/respond.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="library/highlight/default.css"
      type="text/css" />
<script src="library/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="library/navigation-1.1/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="fluid-row" id="header">




</div>


<div id="data-import" class="section level1 tabset">
<h1>Data import</h1>
<div id="library" class="section level2">
<h2>Library</h2>
<pre class="r"><code>library(formr)
library(devtools)
library(haven)
# devtools::install_github(&quot;hadley/haven&quot;)
library(plyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(dplyr)</code></pre>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:plyr&#39;:
## 
##     arrange, count, desc, failwith, id, mutate, rename, summarise,
##     summarize</code></pre>
<pre><code>## The following objects are masked from &#39;package:formr&#39;:
## 
##     first, last</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
</div>
<div id="helper" class="section level2">
<h2>Helper</h2>
<pre class="r"><code>all_available_info_birth_date = function(byear, bmonth, bday = NULL) {
  if(!is.null(bday)) {
    bday = paste0(&quot;-&quot;, bday)
  } else {
    bday = &quot;&quot;
  }
  ifelse(is.na(byear), NA,
         paste0(byear, &quot;-&quot;, bmonth, bday))
  # can yield 2016-NA-NA
  #           2016-01-NA
  #           2016-01-01
  #           2016-01
}

#&#39; ##### only older sibs
older_sibs_alive_and_dependent = function(byear, dyear) {
    sibs = length(byear)
    older_sibs_alive_and_dependent = integer(length=sibs)
    for(i in 1:sibs) {
        older_sibs = byear &lt;= byear[i] # not using &lt; because of twins
        older_sibs[i] = F # minus self
        my_sibs = sum(older_sibs,na.rm = T) # minus self
        if(my_sibs &gt; 0) {
            sib_births = byear[ which(older_sibs) ]
            sib_deaths = dyear[ which(older_sibs) ]
            my_sibs = my_sibs -
                sum(
                    # sib_births &lt; (byear[i] - 5) | # others born more than 5y earlier than me  # 10 seconds of 17
                        (sib_deaths &lt;= byear[i]) # died before my birth
                ,na.rm=T)
            older_sibs_alive_and_dependent[i] = my_sibs
        }
    }
    older_sibs_alive_and_dependent
}</code></pre>
</div>
<div id="load-data" class="section level2">
<h2>Load data</h2>
<pre class="r"><code>### Individual and household Information
## Informations about individuals living in the household in 2014/2015
# Individuals living in the household
bk_ar1 = read_dta(&quot;data/hh14_all_dta/bk_ar1.dta&quot;)
# Additional information from mothers
b4_ba6 = read_dta(&quot;data/hh14_all_dta/b4_ba6.dta&quot;)

# compute father pidlink
bk_ar1 = left_join(bk_ar1, bk_ar1 %&gt;% select(hhid14_9, pid14, pidlink) %&gt;% rename(ar10 = pid14, father_pidlink = pidlink), by = c(&quot;hhid14_9&quot;, &quot;ar10&quot;))
# compute mother pidlink
bk_ar1 = left_join(bk_ar1, bk_ar1 %&gt;% select(hhid14_9, pid14, pidlink) %&gt;% rename(ar11 = pid14, mother_pidlink = pidlink), by = c(&quot;hhid14_9&quot;, &quot;ar11&quot;))

### Informations about earlier waves
ptrack = read_dta(&quot;data/hh14_all_dta/ptrack.dta&quot;)

### IQ Information
ek_ek2 = read_dta(&quot;data/hh14_all_dta/ek_ek2.dta&quot;) # over 15yo
ek_time2 = read_dta(&quot;data/hh14_all_dta/ek_time2.dta&quot;)
# additional information (counting backwards, adaptive testing) for adults
b3b_cob = read_dta(&quot;data/hh14_all_dta/b3b_cob.dta&quot;) # over 15yo
b3b_co1 = read_dta(&quot;data/hh14_all_dta/b3b_co1.dta&quot;) # over 15yo
### Personality Information (only for adults)
b3b_psn = read_dta(&quot;data/hh14_all_dta/b3b_psn.dta&quot;) # over 15yo

### Risk taking
b3a_si = read_dta(&quot;data/hh14_all_dta/b3a_si.dta&quot;)</code></pre>
</div>
<div id="select-individual-data" class="section level2">
<h2>Select individual data</h2>
<pre class="r"><code>### Individuals
individuals = bk_ar1 %&gt;% select(hhid14_9, pidlink, father_pidlink, mother_pidlink, ar01a, ar02b, ar10, ar11, ar07, ar08day, ar08mth, ar08yr, ar09, ar18h)
#Rename variables to make it easier
individuals &lt;- rename(individuals, relation_to_HH_head = ar02b, fatherID = ar10, motherID = ar11, sex = ar07, age = ar09, alive = ar18h, status = ar01a) 
# Remove duplicats:
table(duplicated(individuals$pidlink))</code></pre>
<pre><code>## 
## FALSE  TRUE 
## 75680 13702</code></pre>
<pre class="r"><code>individuals &lt;- individuals %&gt;% distinct(pidlink, .keep_all = TRUE)


## people whose parents can not be identified have to be marked as NA:
individuals$fatherID[ individuals$fatherID&gt;50] = NA
individuals$motherID[ individuals$motherID&gt;50] = NA

##create number that should be identical for all siblings in one family
individuals &lt;- unite(individuals,
                  col = &quot;hhid14_9_fatherID_motherID&quot;,
                  hhid14_9, fatherID, motherID,
                  sep = &quot;_&quot;,
                  remove = FALSE)
individuals$hhid14_9_fatherID_motherID = ifelse(is.na(individuals$fatherID), NA, individuals$hhid14_9_fatherID_motherID)
individuals$hhid14_9_fatherID_motherID = ifelse(is.na(individuals$motherID), NA, individuals$hhid14_9_fatherID_motherID)

individuals = individuals %&gt;% mutate(
  mother_father_dyad = stringr::str_c(father_pidlink, mother_pidlink)
)

crosstabs( ~ is.na(mother_father_dyad) + is.na(hhid14_9_fatherID_motherID), data = individuals)</code></pre>
<pre><code>##                          is.na(hhid14_9_fatherID_motherID)
## is.na(mother_father_dyad) FALSE  TRUE
##                     FALSE 35649     0
##                     TRUE      0 40031</code></pre>
<pre class="r"><code>n_distinct(individuals$mother_father_dyad)</code></pre>
<pre><code>## [1] 15622</code></pre>
<pre class="r"><code>n_distinct(individuals$hhid14_9_fatherID_motherID)</code></pre>
<pre><code>## [1] 16242</code></pre>
<pre class="r"><code>##calculate sibling size
individuals = individuals %&gt;% 
   group_by(mother_father_dyad) %&gt;%
   mutate(siblingcount = n())
individuals$siblingcount = ifelse(is.na(individuals$fatherID), NA, individuals$siblingcount)
individuals$siblingcount = ifelse(is.na(individuals$motherID), NA, individuals$siblingcount)
qplot(individuals$siblingcount)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 40031 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/select%20individual%20data-1.png" width="672" /></p>
<pre class="r"><code>##calculate birth order
# create date of birth
individuals$ar08day[ individuals$ar08day&gt;31] = NA
individuals$ar08mth[ individuals$ar08mth&gt;12] = NA
individuals$ar08yr[ individuals$ar08yr&gt;2016] = NA
individuals$ar08day[ is.nan(individuals$ar08day) ] = NA
individuals$ar08mth[ is.nan(individuals$ar08mth) ] = NA
individuals$ar08yr[ is.nan(individuals$ar08yr)] = NA

individuals = individuals %&gt;%
    mutate(birth = 
           ifelse(is.na(ar08yr), NA,
           paste0(ar08yr, &quot;-&quot;, ar08mth, &quot;-&quot;, ar08day)
           )
  ) %&gt;%
  group_by(mother_father_dyad) %&gt;%
  mutate(birthorder = min_rank(birth)) %&gt;%
  group_by(mother_father_dyad, birth) %&gt;%
  mutate(multiple_birth = n()) %&gt;%
  group_by(mother_father_dyad) %&gt;%
  mutate(any_multiple_birth_in_fam = any(multiple_birth &gt; 1))

individuals$birthorder = ifelse(is.na(individuals$mother_father_dyad), NA, individuals$birthorder)
individuals$multiple_birth = ifelse(is.na(individuals$mother_father_dyad), NA, individuals$multiple_birth)
individuals$any_multiple_birth_in_fam = ifelse(is.na(individuals$mother_father_dyad), NA, individuals$any_multiple_birth_in_fam)


crosstabs(individuals$birthorder)</code></pre>
<pre><code>## individuals$birthorder
##     1     2     3     4     5     6     7     8     9    10    11  &lt;NA&gt; 
## 15674 10429  5215  2432  1047   488   204    85    35    12     3 40056</code></pre>
<pre class="r"><code>crosstabs(individuals$multiple_birth)</code></pre>
<pre><code>## individuals$multiple_birth
##     1     2     3     4  &lt;NA&gt; 
## 35310   326     9     4 40031</code></pre>
<pre class="r"><code>crosstabs(individuals[!duplicated(individuals$mother_father_dyad), ]$any_multiple_birth_in_fam)</code></pre>
<pre><code>## individuals[!duplicated(individuals$mother_father_dyad), ]$any_multiple_birth_in_fam
## FALSE  TRUE  &lt;NA&gt; 
## 15456   165     1</code></pre>
<pre class="r"><code># only few individuals with missing byears
crosstabs(~ is.na(ar08yr) + is.na(age), data = individuals)</code></pre>
<pre><code>##              is.na(age)
## is.na(ar08yr) FALSE  TRUE
##         FALSE 69027     0
##         TRUE    255  6398</code></pre>
<pre class="r"><code>qplot(individuals$birthorder)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 40056 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/select%20individual%20data-2.png" width="672" /></p>
</div>
<div id="compare-with-mother-information" class="section level2">
<h2>Compare with mother information</h2>
<pre class="r"><code>motherinformations = b4_ba6 %&gt;% select(hhid14_9, pidlink, ba63cx, ba64, ba64bmt, ba64byr, ba64c, ba65, ba65mt, ba65ayr, ba66, ba63n)

#Rename variables to make it easier
motherinformations &lt;- rename(motherinformations, biologicalchild_m = ba63cx, sex_m = ba64,  birth_month_m = ba64bmt, birth_year_m = ba64byr, living_in_HH_m = ba64c, alive_m = ba65, death_month_m = ba65mt, death_year_m = ba65ayr, death_age_m = ba66,total_number_childs_m = ba63n, mother_pidlink = pidlink) 

# Mothercheck
individuals$mother_reported_on_other_sibs = ifelse(individuals$mother_pidlink %in% motherinformations$mother_pidlink, 1, 0)
crosstabs(individuals$mother_reported_on_other_sibs)</code></pre>
<pre><code>## individuals$mother_reported_on_other_sibs
##     0     1 
## 58127 17553</code></pre>
<pre class="r"><code>motherinformations$birth_year_m = (ifelse(motherinformations$birth_year_m&lt;2016, motherinformations$birth_year_m, NA))

motherinformations$birth_month_m = (ifelse(motherinformations$birth_month_m&lt;13, motherinformations$birth_month_m, NA))

motherinformations$death_year_m = (ifelse(motherinformations$death_year_m&lt;2016, motherinformations$death_year_m, NA))

motherinformations$death_month_m = (ifelse(motherinformations$death_month_m&lt;13, motherinformations$death_month_m, NA))

missingness_patterns(motherinformations %&gt;% select(mother_pidlink, birth_year_m, birth_month_m))</code></pre>
<pre><code>##  index           col missings
##      1 birth_month_m     2716
##      2  birth_year_m     1855</code></pre>
<pre><code>##   Pattern  Freq       Culprit
## 1     ___ 15901             _
## 2     1_2  1853              
## 3     1__   863 birth_month_m
## 4     __2     2  birth_year_m</code></pre>
<pre class="r"><code>motherinformations = motherinformations %&gt;%
    mutate(mother_birthdate = str_c(mother_pidlink, 
          all_available_info_birth_date(birth_year_m, birth_month_m) ))

# remove all with unknown mothers/unknown birthmonths
motherinformations = motherinformations %&gt;%
  filter(!is.na(mother_birthdate))

individuals = individuals %&gt;%
    mutate(mother_birthdate = str_c(mother_pidlink, 
          all_available_info_birth_date(ar08yr, ar08mth) ))

# remove all with unknown mothers/unknown birthmonths
crosstabs(~ is.na(mother_birthdate) + mother_reported_on_other_sibs, data = individuals)</code></pre>
<pre><code>##                        mother_reported_on_other_sibs
## is.na(mother_birthdate)     0     1
##                   FALSE 23913 17552
##                   TRUE  34214     1</code></pre>
<pre class="r"><code>individuals = individuals %&gt;%
  filter(!is.na(mother_birthdate), mother_reported_on_other_sibs == 1)


# overlap between individuals and motherinfo
length(intersect(individuals$mother_birthdate, motherinformations$mother_birthdate))</code></pre>
<pre><code>## [1] 13858</code></pre>
<pre class="r"><code>ind_mbd = na.omit(individuals$mother_birthdate)
ind_dupes = unique(ind_mbd[duplicated(ind_mbd)])
length(ind_dupes)</code></pre>
<pre><code>## [1] 91</code></pre>
<pre class="r"><code>minfo_mbd = na.omit(motherinformations$mother_birthdate)
minfo_dupes = unique(minfo_mbd[duplicated(minfo_mbd)])
length(minfo_dupes)</code></pre>
<pre><code>## [1] 137</code></pre>
<pre class="r"><code># overlap between duplicates in ind and minfo
intersect(minfo_dupes, ind_dupes)</code></pre>
<pre><code>##  [1] &quot;0032000031997-5&quot;  &quot;0050300022007-8&quot;  &quot;0072500021999-11&quot;
##  [4] &quot;0081500021991-7&quot;  &quot;0102700021999-6&quot;  &quot;0112700032010-9&quot; 
##  [7] &quot;0161300141999-5&quot;  &quot;0211841022001-9&quot;  &quot;0250700042007-2&quot; 
## [10] &quot;0332300092007-9&quot;  &quot;0341541022011-6&quot;  &quot;0350100021991-6&quot; 
## [13] &quot;0481631021998-8&quot;  &quot;0482200021987-2&quot;  &quot;0501700021982-12&quot;
## [16] &quot;0511400021987-6&quot;  &quot;0552000061999-1&quot;  &quot;0552012021996-1&quot; 
## [19] &quot;0620100022002-9&quot;  &quot;0680511022006-2&quot;  &quot;0680600021987-11&quot;
## [22] &quot;0784400022000-3&quot;  &quot;0910600082002-9&quot;  &quot;0990800042007-5&quot; 
## [25] &quot;1040100021987-1&quot;  &quot;1051800021995-5&quot;  &quot;1130200042003-8&quot; 
## [28] &quot;1130600082004-8&quot;  &quot;1141600052008-4&quot;  &quot;1221900032007-10&quot;
## [31] &quot;1320600021992-7&quot;  &quot;1391000062005-8&quot;  &quot;1440500021991-9&quot; 
## [34] &quot;1452500062004-5&quot;  &quot;1651500021992-9&quot;  &quot;1672500041990-6&quot; 
## [37] &quot;1682600021992-4&quot;  &quot;1700700031998-3&quot;  &quot;1721500102005-10&quot;
## [40] &quot;1732500021981-6&quot;  &quot;1732900052007-4&quot;  &quot;1761000032009-8&quot; 
## [43] &quot;1780100031999-3&quot;  &quot;1861000031985-9&quot;  &quot;1891341022007-7&quot; 
## [46] &quot;1960700051990-11&quot; &quot;1971300062008-1&quot;  &quot;2111300021985-8&quot; 
## [49] &quot;2191800032005-4&quot;  &quot;2261800022004-1&quot;  &quot;2340500021990-2&quot; 
## [52] &quot;2380200021996-8&quot;  &quot;2461332022005-2&quot;  &quot;2501300032003-8&quot; 
## [55] &quot;2521641022009-11&quot; &quot;2711900032005-1&quot;  &quot;2720800021998-5&quot; 
## [58] &quot;2740200021984-7&quot;  &quot;2740800021990-5&quot;  &quot;2741700022001-1&quot; 
## [61] &quot;2761900022003-8&quot;  &quot;2771200072005-8&quot;  &quot;2792100022003-1&quot; 
## [64] &quot;2830500021987-8&quot;  &quot;2851500022005-1&quot;  &quot;2871900022004-8&quot; 
## [67] &quot;2880100021995-6&quot;  &quot;2921431022003-2&quot;  &quot;2951100022000-12&quot;
## [70] &quot;2971031021997-11&quot; &quot;3031600021996-9&quot;  &quot;3051300021994-7&quot; 
## [73] &quot;3060332022005-4&quot;  &quot;3071631032005-6&quot;  &quot;3090600052006-7&quot; 
## [76] &quot;3152900021983-3&quot;  &quot;3154100082000-7&quot;</code></pre>
<pre class="r"><code># suboptimal solution: because twins and triplets are not uniquely identified in the motherinformations file. We&#39;re using the mother informations file mainly to get sibs MISSING from the indidivuals file, so this is not a big deal. We also get death dates &gt; 12m ago from the minfo file, but individuals who died &gt;12m ago are not in the individuals file.
motherinformations = motherinformations %&gt;% filter(! mother_birthdate %in% intersect(minfo_dupes, ind_dupes))

length(union(motherinformations$mother_birthdate, individuals$mother_birthdate)) # expected size of parentscheck minus twins</code></pre>
<pre><code>## [1] 20227</code></pre>
<pre class="r"><code>parentscheck = full_join(individuals, motherinformations, by = &quot;mother_birthdate&quot;)
nrow(parentscheck)</code></pre>
<pre><code>## [1] 20380</code></pre>
<pre class="r"><code>parentscheck = parentscheck %&gt;% aggregate2sources(&quot;mother_pidlink&quot;, &quot;mother_pidlink.x&quot;, &quot;mother_pidlink.y&quot;)</code></pre>
<pre><code>## 2779  fewer missings</code></pre>
<pre class="r"><code>parentscheck = parentscheck %&gt;%
  filter(!is.na(mother_birthdate), !is.na(mother_pidlink))


bk_ar1$ar18h = as.numeric(as.character(bk_ar1$ar18h))
bk_ar1$ar18h[is.nan(bk_ar1$ar18h)] = NA
crosstabs(~ ar01a + ar18h, data = bk_ar1)</code></pre>
<pre><code>##      ar18h
## ar01a     1     3     8     9  &lt;NA&gt;
##    0      0     0     0     0  6438
##    1      0     0     0     0 33924
##    2      0     0     0     0  7480
##    3  23864    20   489    11     0
##    5      0     0     0     0 16853
##    6      0     0     0     0   248
##    11     0     0     0     0    55</code></pre>
<pre class="r"><code>crosstabs(~ bk_ar1$ar01a)</code></pre>
<pre><code>## bk_ar1$ar01a
##     0     1     2     3     5     6    11 
##  6438 33924  7480 24384 16853   248    55</code></pre>
<pre class="r"><code>crosstabs(parentscheck$alive_m + parentscheck$status) # almost no one died in last12m?</code></pre>
<pre><code>##                     parentscheck$status
## parentscheck$alive_m    1    2    3    5   11 &lt;NA&gt;
##                 1     143   45 4100    0   17 1612
##                 3       1    3    4    0    0  386
##                 8       0    0    1    0    0    1
##                 &lt;NA&gt;  792   73  753 2140    7    0
##                 NaN  7758  444  858  459    3  780</code></pre>
<pre class="r"><code>### Social Birthorder - siblings by the time of birth
parentscheck$alive_m = ifelse(is.na(parentscheck$alive_m), 1, parentscheck$alive_m)
qplot(parentscheck$alive_m)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="1_data_import_files/figure-html/compare%20with%20mother%20information-1.png" width="672" /></p>
<pre class="r"><code>qplot(parentscheck$death_age_m, binwidth=1)</code></pre>
<pre><code>## Warning: Removed 14077 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/compare%20with%20mother%20information-2.png" width="672" /></p>
<pre class="r"><code># all who&#39;re dead in our subset have their death date in minfo
parentscheck = parentscheck %&gt;% mutate(
  death_year_m_agg = ifelse(is.na(death_year_m), birth_year_m + death_age_m, death_year_m),
  death_date = all_available_info_birth_date(death_year_m_agg, death_month_m))

### Biological Birthorder: Order in Uterus
# only include biological childs
parentscheck$biologicalchild_m = ifelse(
  is.na(parentscheck$biologicalchild_m), 1, # those who don&#39;t have this var are from the individuals file and are biological kids
  parentscheck$biologicalchild_m) # the ones from the minfo file can have a zero here (be adopted)

parentscheck = parentscheck %&gt;%
    mutate(birth_ind = all_available_info_birth_date(ar08yr, ar08mth, ar08day),
           birth_minfo = all_available_info_birth_date(birth_year_m, birth_month_m)) %&gt;%
    aggregate2sources(&quot;birth&quot;, &quot;birth_ind&quot;, &quot;birth_minfo&quot;)</code></pre>
<pre><code>## Warning in aggregate2sources(., &quot;birth&quot;, &quot;birth_ind&quot;, &quot;birth_minfo&quot;):
## birth already exists. Maybe delete it or choose a different name, if you&#39;re
## saving over your original dataframe.</code></pre>
<pre><code>## 2779  fewer missings</code></pre>
<pre class="r"><code>parentscheck = parentscheck %&gt;%
  group_by(mother_pidlink) %&gt;%
  mutate(
    birth_bio = ifelse(biologicalchild_m == 1, birth, NA),
    birthorder_uterus = min_rank(birth_bio),
    siblingcount_maternal = sum(biologicalchild_m == 1),
    
    born_lived_5y = ifelse(death_age_m &lt;= 5, NA, birth),
    birthorder_min5y = min_rank(born_lived_5y),
    siblingcount_min5y = sum(is.na(born_lived_5y)),
    
    birthorder_alive = older_sibs_alive_and_dependent(as.numeric(str_sub(birth, 1, 4)), death_year_m)
    
  ) %&gt;%
  group_by(mother_pidlink, birth) %&gt;% # adopt
  mutate(multiple_birth = sum(biologicalchild_m == 1)) %&gt;%
  group_by(mother_pidlink) %&gt;%
  mutate(any_multiple_birth_in_fam = any(multiple_birth &gt; 1))

ggplot(parentscheck, aes(x=siblingcount_maternal, y=birthorder_uterus)) + geom_jitter()</code></pre>
<pre><code>## Warning: Removed 832 rows containing missing values (geom_point).</code></pre>
<p><img src="1_data_import_files/figure-html/compare%20with%20mother%20information-3.png" width="672" /></p>
<pre class="r"><code>ggplot(parentscheck, aes(x=siblingcount_maternal, y=birthorder_uterus)) + geom_jitter()</code></pre>
<pre><code>## Warning: Removed 832 rows containing missing values (geom_point).</code></pre>
<p><img src="1_data_import_files/figure-html/compare%20with%20mother%20information-4.png" width="672" /></p>
<pre class="r"><code># how to compute social birth order
# count only those who&#39;re alive at own time of birth?
# count only those who survived their own infancy?

crosstabs(parentscheck$birthorder_min5y)</code></pre>
<pre><code>## parentscheck$birthorder_min5y
##     1     2     3     4     5     6     7     8     9  &lt;NA&gt; 
##  2935  1644   819   390   182    74    35    16     5 14280</code></pre>
<pre class="r"><code>qplot(parentscheck$birthorder_min5y, parentscheck$birthorder_uterus, geom = &#39;jitter&#39;)</code></pre>
<pre><code>## Warning: Removed 14995 rows containing missing values (geom_point).</code></pre>
<p><img src="1_data_import_files/figure-html/compare%20with%20mother%20information-5.png" width="672" /></p>
<pre class="r"><code>crosstabs(~ birthorder_min5y + birthorder_uterus, data = parentscheck)</code></pre>
<pre><code>##                 birthorder_uterus
## birthorder_min5y    1    2    3    4    5    6    7    8    9   10   11
##             1    2130  399   73   16    1    2    2    0    0    0    0
##             2      68  973  316   80   20    5    0    0    0    0    0
##             3      26   43  402  167   55   18    5    2    2    1    0
##             4      16   19   20  156   77   27   14    2    4    1    0
##             5       9    6    5   11   56   35   16    8    2    1    1
##             6       1    9    3    1    3   21    6    6    3    1    0
##             7       2    1    8    2    0    1    5    5    1    2    0
##             8       0    2    1    2    0    0    0    3    1    0    1
##             9       0    0    0    0    1    0    0    0    1    0    0
##             &lt;NA&gt; 4337 4424 2656 1333  672  359  186   96   49   26   14
##                 birthorder_uterus
## birthorder_min5y   12   13   14 &lt;NA&gt;
##             1       0    0    0  312
##             2       0    0    0  182
##             3       0    0    0   98
##             4       0    0    0   54
##             5       0    0    0   32
##             6       0    0    0   20
##             7       0    0    0    8
##             8       0    0    0    6
##             9       0    0    0    3
##             &lt;NA&gt;    7    2    2  117</code></pre>
<pre class="r"><code>crosstabs(~ birthorder_alive + birthorder_uterus, data = parentscheck)</code></pre>
<pre><code>##                 birthorder_uterus
## birthorder_alive    1    2    3    4    5    6    7    8    9   10   11
##               0  6014   45    2    0    0    0    0    0    0    0    0
##               1   437 5372   72    6    0    0    0    0    0    0    0
##               2    69  327 3064   47    6    0    0    0    0    0    0
##               3    40   73  248 1514   28    3    1    0    0    0    0
##               4    20   27   42  149  731   20    1    1    0    0    0
##               5     6   18   25   21  104  384   11    0    0    0    0
##               6     2   11   19   13    5   51  190   10    0    0    0
##               7     1    1    9    9    4    5   27   98    5    0    0
##               8     0    2    1    5    4    2    3    9   50    1    0
##               9     0    0    1    2    2    2    0    4    7   24    0
##               10    0    0    0    1    0    0    0    0    0    7   15
##               11    0    0    1    1    0    0    0    0    1    0    1
##               12    0    0    0    0    1    0    0    0    0    0    0
##               13    0    0    0    0    0    1    0    0    0    0    0
##               14    0    0    0    0    0    0    1    0    0    0    0
##                 birthorder_uterus
## birthorder_alive   12   13   14 &lt;NA&gt;
##               0     0    0    0  317
##               1     0    0    0  191
##               2     0    0    0  128
##               3     0    0    0   84
##               4     0    0    0   49
##               5     0    0    0   22
##               6     0    0    0   17
##               7     0    0    0   15
##               8     0    0    0    4
##               9     0    0    0    2
##               10    1    0    0    2
##               11    6    0    0    1
##               12    0    2    0    0
##               13    0    0    2    0
##               14    0    0    0    0</code></pre>
<pre class="r"><code>qplot(parentscheck$birthorder_alive, parentscheck$birthorder_uterus, geom = &#39;jitter&#39;)</code></pre>
<pre><code>## Warning: Removed 832 rows containing missing values (geom_point).</code></pre>
<p><img src="1_data_import_files/figure-html/compare%20with%20mother%20information-6.png" width="672" /></p>
<pre class="r"><code>table(parentscheck$living_in_HH_m==3)</code></pre>
<pre><code>## 
## FALSE  TRUE 
## 10302  6313</code></pre>
<pre class="r"><code>parentscheck = parentscheck %&gt;% 
   group_by(mother_pidlink) %&gt;%
   mutate(siblingcount_total = n())



individuals_parents_checked = filter(parentscheck, age&gt;14)</code></pre>
</div>
<div id="select-iq-data" class="section level2">
<h2>Select IQ data</h2>
<pre class="r"><code>### IQ Informations
##ek2 (&gt;14yrs)
iq2.1 = ek_ek2 %&gt;% select(hhid14_9, pidlink, age, sex, ektype, resptype, result, reason, ek1_ans, ek2_ans, ek3_ans, ek4_ans, ek5_ans, ek6_ans, ek7_ans, ek8_ans, ek9_ans, ek10_ans, ek11_ans, ek12_ans, ek13_ans, ek14_ans, ek15_ans, ek16_ans, ek17_ans, ek18_ans, ek19_ans, ek20_ans, ek21_ans, ek22_ans)


##additional informations for adults: counting backwards
iq2.2 = b3b_co1 %&gt;% select(hhid14_9, pidlink, co04a, co04b, co04c, co04d, co04e, co07count, co10count)
##additional informations for adults: adaptive number test
iq2.3 = b3b_cob %&gt;% select(hhid14_9, pidlink, w_abil, cob18, cob19b)

## put all the informations for participants &gt;= 15 together
iq2 = full_join(iq2.1, iq2.2, by = &quot;pidlink&quot;)
iq2 = full_join(iq2, iq2.3, by = &quot;pidlink&quot;)
iq = iq2
iq &lt;- plyr::rename(iq, c(&quot;age&quot;=&quot;IQage&quot;)) 

### calculate iq scores
##Raven Test
answered_raven_items = iq %&gt;% select(ek1_ans:ek6_ans, ek11_ans, ek12_ans)
psych::alpha(data.frame(answered_raven_items))</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = data.frame(answered_raven_items))
## 
##   raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd
##       0.85      0.85    0.84      0.41 5.5 0.0012 0.53 0.33
## 
##  lower alpha upper     95% confidence boundaries
## 0.85 0.85 0.85 
## 
##  Reliability if an item is dropped:
##          raw_alpha std.alpha G6(smc) average_r S/N alpha se
## ek1_ans       0.82      0.82    0.81      0.39 4.5   0.0014
## ek2_ans       0.81      0.81    0.80      0.38 4.3   0.0015
## ek3_ans       0.81      0.81    0.80      0.38 4.3   0.0015
## ek4_ans       0.82      0.81    0.81      0.38 4.4   0.0014
## ek5_ans       0.83      0.83    0.83      0.41 4.9   0.0013
## ek6_ans       0.85      0.85    0.84      0.44 5.6   0.0012
## ek11_ans      0.83      0.82    0.82      0.40 4.6   0.0014
## ek12_ans      0.86      0.86    0.85      0.46 5.9   0.0011
## 
##  Item statistics 
##              n raw.r std.r r.cor r.drop mean   sd
## ek1_ans  36380  0.74  0.74  0.71   0.65 0.74 0.44
## ek2_ans  36380  0.80  0.80  0.79   0.72 0.67 0.47
## ek3_ans  36380  0.79  0.79  0.77   0.71 0.58 0.49
## ek4_ans  36380  0.78  0.77  0.74   0.69 0.59 0.49
## ek5_ans  36380  0.68  0.68  0.60   0.56 0.50 0.50
## ek6_ans  36380  0.54  0.55  0.44   0.40 0.28 0.45
## ek11_ans 36380  0.73  0.72  0.67   0.62 0.61 0.49
## ek12_ans 36380  0.47  0.49  0.36   0.34 0.22 0.42
## 
## Non missing response frequency for each item
##             0    1 miss
## ek1_ans  0.26 0.74    0
## ek2_ans  0.33 0.67    0
## ek3_ans  0.42 0.58    0
## ek4_ans  0.41 0.59    0
## ek5_ans  0.50 0.50    0
## ek6_ans  0.72 0.28    0
## ek11_ans 0.39 0.61    0
## ek12_ans 0.78 0.22    0</code></pre>
<pre class="r"><code>iq$raven = rowMeans( answered_raven_items, na.rm = T)
iq$raven[! iq$result %in% 1:2] = NA
qplot(iq$raven)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 5049 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/select%20IQ%20data-1.png" width="672" /></p>
<pre class="r"><code>##Math Test
answered_math_items = iq %&gt;% select(ek18_ans:ek22_ans)
psych::alpha(data.frame(answered_math_items))</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = data.frame(answered_math_items))
## 
##   raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd
##       0.68      0.68    0.64       0.3 2.1 0.0026 0.26 0.29
## 
##  lower alpha upper     95% confidence boundaries
## 0.68 0.68 0.69 
## 
##  Reliability if an item is dropped:
##          raw_alpha std.alpha G6(smc) average_r S/N alpha se
## ek18_ans      0.68      0.67    0.61      0.34 2.1   0.0027
## ek19_ans      0.60      0.60    0.54      0.28 1.5   0.0033
## ek20_ans      0.60      0.60    0.53      0.27 1.5   0.0034
## ek21_ans      0.66      0.65    0.60      0.32 1.9   0.0029
## ek22_ans      0.63      0.62    0.56      0.29 1.7   0.0032
## 
##  Item statistics 
##              n raw.r std.r r.cor r.drop mean   sd
## ek18_ans 36380  0.59  0.59  0.41   0.34 0.25 0.43
## ek19_ans 36380  0.71  0.71  0.61   0.50 0.28 0.45
## ek20_ans 36380  0.73  0.72  0.63   0.51 0.34 0.47
## ek21_ans 36380  0.60  0.63  0.46   0.38 0.18 0.38
## ek22_ans 36380  0.68  0.68  0.55   0.46 0.28 0.45
## 
## Non missing response frequency for each item
##             0    1 miss
## ek18_ans 0.75 0.25    0
## ek19_ans 0.72 0.28    0
## ek20_ans 0.66 0.34    0
## ek21_ans 0.82 0.18    0
## ek22_ans 0.72 0.28    0</code></pre>
<pre class="r"><code>iq$math = rowMeans( answered_math_items, na.rm = T)
iq$math[! iq$result %in% 1:2] = NA
qplot(iq$math)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 5049 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/select%20IQ%20data-2.png" width="672" /></p>
<pre class="r"><code>##Counting Items
# Create Right/Wrong Scores for the counting items
iq$co04aright = as.numeric(iq$co04a == 93)
iq$co04bright = as.numeric(iq$co04b == iq$co04a-7)
iq$co04cright = as.numeric(iq$co04c == iq$co04b-7)
iq$co04dright = as.numeric(iq$co04d == iq$co04c-7)
iq$co04eright = as.numeric(iq$co04e == iq$co04d-7)

answered_counting_items = iq %&gt;% select(co04aright:co04eright)
psych::alpha(data.frame(answered_counting_items))</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = data.frame(answered_counting_items))
## 
##   raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd
##       0.69      0.68    0.64      0.29 2.1 0.0024 0.73 0.29
## 
##  lower alpha upper     95% confidence boundaries
## 0.68 0.69 0.69 
## 
##  Reliability if an item is dropped:
##            raw_alpha std.alpha G6(smc) average_r S/N alpha se
## co04aright      0.71      0.71    0.65      0.38 2.4   0.0025
## co04bright      0.64      0.62    0.57      0.29 1.6   0.0028
## co04cright      0.60      0.59    0.54      0.27 1.5   0.0030
## co04dright      0.61      0.60    0.54      0.27 1.5   0.0030
## co04eright      0.60      0.59    0.54      0.27 1.5   0.0031
## 
##  Item statistics 
##                n raw.r std.r r.cor r.drop mean   sd
## co04aright 30452  0.43  0.51  0.27   0.23 0.95 0.22
## co04bright 29661  0.70  0.67  0.53   0.45 0.63 0.48
## co04cright 29260  0.73  0.71  0.61   0.52 0.69 0.46
## co04dright 29078  0.73  0.71  0.61   0.51 0.69 0.46
## co04eright 28983  0.73  0.71  0.61   0.52 0.70 0.46
## 
## Non missing response frequency for each item
##               0    1 miss
## co04aright 0.05 0.95 0.16
## co04bright 0.37 0.63 0.18
## co04cright 0.31 0.69 0.20
## co04dright 0.31 0.69 0.20
## co04eright 0.30 0.70 0.20</code></pre>
<pre class="r"><code>iq$count_backwards = rowSums( answered_counting_items, na.rm = T) / 5
qplot(iq$count_backwards)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="1_data_import_files/figure-html/select%20IQ%20data-3.png" width="672" /></p>
<pre class="r"><code>## Word Memory
iq$words_immediate = iq$co07count
iq$words_delayed = iq$co10count
qplot(iq$words_immediate, iq$words_delayed, geom = &quot;jitter&quot;)</code></pre>
<pre><code>## Warning: Removed 4917 rows containing missing values (geom_point).</code></pre>
<p><img src="1_data_import_files/figure-html/select%20IQ%20data-4.png" width="672" /></p>
<pre class="r"><code>answered_word_items = iq %&gt;% select(co07count,co10count)
psych::alpha(data.frame(answered_word_items))</code></pre>
<pre><code>## Warning in matrix(unlist(drop.item), ncol = 8, byrow = TRUE): data length
## [12] is not a sub-multiple or multiple of the number of columns [8]</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = data.frame(answered_word_items))
## 
##   raw_alpha std.alpha G6(smc) average_r S/N    ase mean  sd
##       0.87      0.87    0.77      0.77 6.8 0.0014  4.6 1.8
## 
##  lower alpha upper     95% confidence boundaries
## 0.87 0.87 0.87 
## 
##  Reliability if an item is dropped:
##           raw_alpha std.alpha G6(smc) average_r  S/N alpha se
## co07count      0.77      0.77     0.6      0.77   NA       NA
## co10count      0.60      0.77      NA        NA 0.77   0.0046
## 
##  Item statistics 
##               n raw.r std.r r.cor r.drop mean  sd
## co07count 31471  0.94  0.94  0.83   0.77  5.1 1.8
## co10count 31471  0.94  0.94  0.83   0.77  4.2 1.9</code></pre>
<pre class="r"><code>iq$words_remembered_avg = rowMeans( answered_word_items, na.rm = T)
qplot(iq$words_remembered_avg)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 4917 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/select%20IQ%20data-5.png" width="672" /></p>
<pre class="r"><code>##Adaptive Numbering
iq$adaptive_numbering = iq$w_abil


#iq$drew_pentagons = as.numeric(iq$cob19b == 1)
#iq$number_of_animals = iq$cob18

## Correlation of all Iq-Tests
round(cor(iq %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering), use = &quot;pairwise.complete.obs&quot;), 2)</code></pre>
<pre><code>##                    raven math count_backwards words_immediate
## raven               1.00 0.41            0.32            0.38
## math                0.41 1.00            0.26            0.31
## count_backwards     0.32 0.26            1.00            0.33
## words_immediate     0.38 0.31            0.33            1.00
## words_delayed       0.37 0.31            0.30            0.77
## adaptive_numbering  0.45 0.35            0.40            0.40
##                    words_delayed adaptive_numbering
## raven                       0.37               0.45
## math                        0.31               0.35
## count_backwards             0.30               0.40
## words_immediate             0.77               0.40
## words_delayed               1.00               0.37
## adaptive_numbering          0.37               1.00</code></pre>
<pre class="r"><code>##Missingness_Patterns
formr::missingness_patterns(iq %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering))</code></pre>
<pre><code>##  index                col missings
##      1              raven     5049
##      2               math     5049
##      3 adaptive_numbering     4979
##      4    words_immediate     4917
##      5      words_delayed     4917</code></pre>
<pre><code>##     Pattern  Freq            Culprit
## 1 _________ 31000                  _
## 2 1_2_3_4_5  4593                   
## 3 1_2______   409                   
## 4 ____3_4_5   324                   
## 5 1_2_3____    47                   
## 6 ____3____    15 adaptive_numbering</code></pre>
</div>
<div id="compute-g-factor" class="section level2">
<h2>compute g factor</h2>
<pre class="r"><code>library(psych)</code></pre>
<pre><code>## 
## Attaching package: &#39;psych&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:ggplot2&#39;:
## 
##     %+%, alpha</code></pre>
<pre class="r"><code>fa.parallel(iq %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering) %&gt;% data.frame())</code></pre>
<p><img src="1_data_import_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre><code>## Parallel analysis suggests that the number of factors =  2  and the number of components =  1</code></pre>
<pre class="r"><code>fa(iq %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering) %&gt;% data.frame())</code></pre>
<pre><code>## Factor Analysis using method =  minres
## Call: fa(r = iq %&gt;% select(raven, math, count_backwards, words_immediate, 
##     words_delayed, adaptive_numbering) %&gt;% data.frame())
## Standardized loadings (pattern matrix) based upon correlation matrix
##                     MR1   h2   u2 com
## raven              0.55 0.30 0.70   1
## math               0.45 0.21 0.79   1
## count_backwards    0.46 0.21 0.79   1
## words_immediate    0.81 0.66 0.34   1
## words_delayed      0.80 0.64 0.36   1
## adaptive_numbering 0.56 0.31 0.69   1
## 
##                 MR1
## SS loadings    2.33
## Proportion Var 0.39
## 
## Mean item complexity =  1
## Test of the hypothesis that 1 factor is sufficient.
## 
## The degrees of freedom for the null model are  15  and the objective function was  1.88 with Chi Square of  68233.51
## The degrees of freedom for the model are 9  and the objective function was  0.32 
## 
## The root mean square of the residuals (RMSR) is  0.09 
## The df corrected root mean square of the residuals is  0.12 
## 
## The harmonic number of observations is  31392 with the empirical chi square  7933.27  with prob &lt;  0 
## The total number of observations was  36388  with MLE Chi Square =  11667.14  with prob &lt;  0 
## 
## Tucker Lewis Index of factoring reliability =  0.715
## RMSEA index =  0.189  and the 90 % confidence intervals are  0.186 0.192
## BIC =  11572.62
## Fit based upon off diagonal values = 0.95
## Measures of factor score adequacy             
##                                                 MR1
## Correlation of scores with factors             0.91
## Multiple R square of scores with factors       0.83
## Minimum correlation of possible factor scores  0.65</code></pre>
<pre class="r"><code>omega(iq %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering) %&gt;% data.frame())</code></pre>
<pre><code>## Loading required namespace: GPArotation</code></pre>
<p><img src="1_data_import_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
<pre><code>## Omega 
## Call: omega(m = iq %&gt;% select(raven, math, count_backwards, words_immediate, 
##     words_delayed, adaptive_numbering) %&gt;% data.frame())
## Alpha:                 0.79 
## G.6:                   0.79 
## Omega Hierarchical:    0.68 
## Omega H asymptotic:    0.81 
## Omega Total            0.85 
## 
## Schmid Leiman Factor loadings greater than  0.2 
##                       g   F1*   F2*   F3*   h2   u2   p2
## raven              0.65        0.39       0.57 0.43 0.73
## math               0.49        0.22       0.30 0.70 0.82
## count_backwards    0.51              0.28 0.34 0.66 0.77
## words_immediate    0.58  0.54             0.63 0.37 0.53
## words_delayed      0.57  0.82             1.00 0.00 0.33
## adaptive_numbering 0.65              0.27 0.50 0.50 0.85
## 
## With eigenvalues of:
##    g  F1*  F2*  F3* 
## 2.01 0.96 0.21 0.16 
## 
## general/max  2.09   max/min =   6.2
## mean percent general =  0.67    with sd =  0.2 and cv of  0.3 
## Explained Common Variance of the general factor =  0.6 
## 
## The degrees of freedom are 0  and the fit is  0 
## The number of observations was  36388  with Chi Square =  0.6  with prob &lt;  NA
## The root mean square of the residuals is  0 
## The df corrected root mean square of the residuals is  NA
## 
## Compare this with the adequacy of just a general factor and no group factors
## The degrees of freedom for just the general factor are 9  and the fit is  0.53 
## The number of observations was  36388  with Chi Square =  19293.51  with prob &lt;  0
## The root mean square of the residuals is  0.12 
## The df corrected root mean square of the residuals is  0.15 
## 
## RMSEA index =  0.243  and the 90 % confidence intervals are  0.24 0.246
## BIC =  19199 
## 
## Measures of factor score adequacy             
##                                                  g  F1*   F2*   F3*
## Correlation of scores with factors            0.84 0.92  0.46  0.40
## Multiple R square of scores with factors      0.70 0.84  0.21  0.16
## Minimum correlation of factor score estimates 0.41 0.69 -0.57 -0.69
## 
##  Total, General and Subset omega for each subset
##                                                  g  F1*  F2*  F3*
## Omega total for total scores and subscales    0.85 0.89 0.60 0.59
## Omega general for total scores and subscales  0.68 0.37 0.46 0.48
## Omega group for total scores and subscales    0.14 0.52 0.13 0.11</code></pre>
<pre class="r"><code>library(lavaan)</code></pre>
<pre><code>## This is lavaan 0.5-22</code></pre>
<pre><code>## lavaan is BETA software! Please report any bugs.</code></pre>
<pre class="r"><code>iq$adaptive_numbering = iq$adaptive_numbering/100
&quot;g_factor =~ raven + math + count_backwards +  words_delayed+ adaptive_numbering&quot; %&gt;%
  cfa(missing = &quot;fiml&quot;, data = iq) -&gt; cfa_g
summary(cfa_g)</code></pre>
<pre><code>## lavaan (0.5-22) converged normally after  46 iterations
## 
##   Number of observations                         36388
## 
##   Number of missing patterns                         6
## 
##   Estimator                                         ML
##   Minimum Function Test Statistic              472.825
##   Degrees of freedom                                 5
##   P-value (Chi-square)                           0.000
## 
## Parameter Estimates:
## 
##   Information                                 Observed
##   Standard Errors                             Standard
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##   g_factor =~                                         
##     raven             1.000                           
##     math              0.890    0.012   76.744    0.000
##     count_backwrds    1.181    0.015   79.028    0.000
##     words_delayed     5.854    0.077   75.827    0.000
##     adaptiv_nmbrng    2.708    0.032   84.413    0.000
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .raven             0.582    0.002  368.756    0.000
##    .math              0.282    0.002  166.076    0.000
##    .count_backwrds    0.595    0.002  297.752    0.000
##    .words_delayed     4.005    0.011  363.733    0.000
##    .adaptiv_nmbrng    5.013    0.004 1192.667    0.000
##     g_factor          0.000                           
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)
##    .raven             0.040    0.000   88.200    0.000
##    .math              0.060    0.001  105.879    0.000
##    .count_backwrds    0.095    0.001   98.166    0.000
##    .words_delayed     2.466    0.023  105.411    0.000
##    .adaptiv_nmbrng    0.271    0.003   85.260    0.000
##     g_factor          0.036    0.001   55.493    0.000</code></pre>
<pre class="r"><code>iq$g_factor = predict(cfa_g)[,1]
qplot(iq$g_factor)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 5388 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/unnamed-chunk-2-3.png" width="672" /></p>
<pre class="r"><code>round(cor(iq %&gt;% select(g_factor, raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering), use = &quot;pairwise.complete.obs&quot;), 2)</code></pre>
<pre><code>##                    g_factor raven math count_backwards words_immediate
## g_factor               1.00  0.77 0.63            0.60            0.61
## raven                  0.77  1.00 0.41            0.32            0.38
## math                   0.63  0.41 1.00            0.26            0.31
## count_backwards        0.60  0.32 0.26            1.00            0.33
## words_immediate        0.61  0.38 0.31            0.33            1.00
## words_delayed          0.64  0.37 0.31            0.30            0.77
## adaptive_numbering     0.79  0.45 0.35            0.40            0.40
##                    words_delayed adaptive_numbering
## g_factor                    0.64               0.79
## raven                       0.37               0.45
## math                        0.31               0.35
## count_backwards             0.30               0.40
## words_immediate             0.77               0.40
## words_delayed               1.00               0.37
## adaptive_numbering          0.37               1.00</code></pre>
<pre class="r"><code>formr::missingness_patterns(iq %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering, g_factor)) ## oops, lavaan only predicts the g factor for complete cases</code></pre>
<pre><code>##  index                col missings
##      1           g_factor     5388
##      2              raven     5049
##      3               math     5049
##      4 adaptive_numbering     4979
##      5    words_immediate     4917
##      6      words_delayed     4917</code></pre>
<pre><code>##       Pattern  Freq Culprit
## 1 ___________ 31000       _
## 2 1_2_3_4_5_6  4593        
## 3 1_2_3______   409        
## 4 1_____4_5_6   324        
## 5 1_2_3_4____    47        
## 6 1_____4____    15</code></pre>
</div>
<div id="select-personality-data" class="section level2">
<h2>Select personality data</h2>
<pre class="r"><code>### Personality
##Rearrange personality data so that every individual has only one row
pers = spread(b3b_psn, psntype, psn01)
##name columns
colnames(pers) &lt;- c(&quot;hhid14_9&quot;, &quot;pid14&quot;, &quot;hhid14&quot;, &quot;pidlink&quot;, &quot;version&quot;, &quot;module&quot;, &quot;e1&quot;, &quot;c1&quot;, &quot;o1&quot;, &quot;e2r&quot;, &quot;n1r&quot;, &quot;a1&quot;, &quot;n2r&quot;, &quot;o2&quot;, &quot;c2r&quot;, &quot;o3&quot;, &quot;a2&quot;, &quot;c3&quot;, &quot;e3&quot;, &quot;a3r&quot;, &quot;n3&quot;)
pers = pers %&gt;% select(hhid14_9, pidlink, e1, c1, o1, e2r, n1r, a1, n2r, o2, c2r, o3, a2, c3, e3, a3r, n3)

##Extraversion
pers$e2r_reversed = 6 - pers$e2r
extraversion = pers %&gt;% select(e1, e2r_reversed, e3)
psych::alpha(data.frame(extraversion), check.keys = T)</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = data.frame(extraversion), check.keys = T)
## 
##   raw_alpha std.alpha G6(smc) average_r  S/N    ase mean   sd
##       0.37      0.35    0.28      0.15 0.54 0.0056  3.4 0.67
## 
##  lower alpha upper     95% confidence boundaries
## 0.36 0.37 0.38 
## 
##  Reliability if an item is dropped:
##              raw_alpha std.alpha G6(smc) average_r   S/N alpha se
## e1               0.072     0.081   0.042     0.042 0.088   0.0092
## e2r_reversed     0.218     0.246   0.140     0.140 0.326   0.0077
## e3               0.429     0.429   0.273     0.273 0.753   0.0064
## 
##  Item statistics 
##                  n raw.r std.r r.cor r.drop mean   sd
## e1           31446  0.77  0.71  0.48   0.30  3.1 1.14
## e2r_reversed 31446  0.73  0.67  0.37   0.24  3.0 1.12
## e3           31446  0.44  0.60  0.19   0.11  4.2 0.67
## 
## Non missing response frequency for each item
##                 1    2    3    4    5 miss
## e1           0.03 0.39 0.08 0.39 0.11    0
## e2r_reversed 0.07 0.36 0.09 0.43 0.05    0
## e3           0.00 0.03 0.05 0.64 0.28    0</code></pre>
<pre class="r"><code>pers$big5_ext = rowMeans(extraversion)
qplot(pers$big5_ext)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="1_data_import_files/figure-html/select%20pesonality%20data-1.png" width="672" /></p>
<pre class="r"><code>##conscientiousness
pers$c2r_reversed = 6 - pers$c2r
conscientiousness = pers %&gt;% select(c1, c2r_reversed, c3)
psych::alpha(data.frame(conscientiousness), check.keys = T)</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = data.frame(conscientiousness), check.keys = T)
## 
##   raw_alpha std.alpha G6(smc) average_r  S/N   ase mean   sd
##       0.29      0.31    0.24      0.13 0.45 0.007  3.8 0.55
## 
##  lower alpha upper     95% confidence boundaries
## 0.27 0.29 0.3 
## 
##  Reliability if an item is dropped:
##              raw_alpha std.alpha G6(smc) average_r  S/N alpha se
## c1                0.10      0.10   0.054     0.054 0.11   0.0101
## c2r_reversed      0.35      0.36   0.219     0.219 0.56   0.0071
## c3                0.20      0.21   0.116     0.116 0.26   0.0087
## 
##  Item statistics 
##                  n raw.r std.r r.cor r.drop mean   sd
## c1           31446  0.61  0.69  0.42   0.23  4.1 0.71
## c2r_reversed 31446  0.65  0.60  0.19   0.10  3.6 0.95
## c3           31446  0.67  0.65  0.34   0.17  3.8 0.90
## 
## Non missing response frequency for each item
##                 1    2    3    4    5 miss
## c1           0.01 0.04 0.04 0.66 0.25    0
## c2r_reversed 0.03 0.18 0.07 0.65 0.07    0
## c3           0.01 0.12 0.08 0.63 0.15    0</code></pre>
<pre class="r"><code>pers$big5_con = rowMeans(conscientiousness)
qplot(pers$big5_con)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="1_data_import_files/figure-html/select%20pesonality%20data-2.png" width="672" /></p>
<pre class="r"><code>##Openness
openness = pers %&gt;% select(o1, o2, o3)
psych::alpha(data.frame(openness), check.keys = T)</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = data.frame(openness), check.keys = T)
## 
##   raw_alpha std.alpha G6(smc) average_r  S/N    ase mean   sd
##       0.45      0.45    0.35      0.21 0.81 0.0054  3.7 0.67
## 
##  lower alpha upper     95% confidence boundaries
## 0.43 0.45 0.46 
## 
##  Reliability if an item is dropped:
##    raw_alpha std.alpha G6(smc) average_r  S/N alpha se
## o1      0.30      0.30    0.18      0.18 0.43   0.0078
## o2      0.39      0.39    0.25      0.25 0.65   0.0068
## o3      0.35      0.36    0.22      0.22 0.55   0.0073
## 
##  Item statistics 
##        n raw.r std.r r.cor r.drop mean   sd
## o1 31446  0.71  0.71  0.45   0.30  3.7 0.98
## o2 31446  0.70  0.67  0.37   0.25  3.5 1.05
## o3 31446  0.65  0.69  0.41   0.27  4.0 0.88
## 
## Non missing response frequency for each item
##       1    2    3    4    5 miss
## o1 0.02 0.18 0.08 0.58 0.14    0
## o2 0.03 0.22 0.09 0.54 0.12    0
## o3 0.01 0.10 0.05 0.61 0.23    0</code></pre>
<pre class="r"><code>pers$big5_open = rowMeans(openness)
qplot(pers$big5_open)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="1_data_import_files/figure-html/select%20pesonality%20data-3.png" width="672" /></p>
<pre class="r"><code>## Neuroticism
pers$n1r_reversed = 6 - pers$n1r
pers$n2r_reversed = 6 - pers$n2r
neuroticism = pers %&gt;% select(n1r_reversed, n2r_reversed, n3)
pers$big5_neu = rowMeans(neuroticism)
qplot(pers$big5_neu)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="1_data_import_files/figure-html/select%20pesonality%20data-4.png" width="672" /></p>
<pre class="r"><code>##Agreeableness
pers$a3r_reversed = 6- pers$a3r
agreeableness= pers %&gt;% select(a1, a2, a3r_reversed)
pers$big5_agree = rowMeans(agreeableness)
qplot(pers$big5_agree)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="1_data_import_files/figure-html/select%20pesonality%20data-5.png" width="672" /></p>
</div>
<div id="select-risk-taking-data" class="section level2">
<h2>Select risk taking data</h2>
<pre class="r"><code>###Risktaking
risk = b3a_si %&gt;% select(hhid14_9, pidlink, random_si, si01, si02, si03, si04, si05, si11, si12, si13, si14, si15)

## 8 means they didnt know which answer they would choose
risk$si01[ risk$si01 == 8] = NA
risk$si02[ risk$si02 == 8] = NA
risk$si03[ risk$si03 == 8] = NA
risk$si04[ risk$si04 == 8] = NA
risk$si05[ risk$si05 == 8] = NA
risk$si11[ risk$si11 == 8] = NA
risk$si12[ risk$si12 == 8] = NA
risk$si13[ risk$si13 == 8] = NA
risk$si14[ risk$si14 == 8] = NA
risk$si15[ risk$si15 == 8] = NA

## calculate a risk score for risk game A 
# (5 = gamble averse, Ordinalskala : 1 = risk loving, 4 = risk averse)
risk$riskA = ifelse(risk$si01 == 1 &amp; risk$si02 == 1, 5,
             ifelse(risk$si01 == 2 &amp; risk$si03 == 1 &amp; risk$si04 == 1, 4,
             ifelse(risk$si01 == 2 &amp; risk$si03 == 1 &amp; risk$si04 == 2, 3,
             ifelse(risk$si01 == 2 &amp; risk$si03 == 2 &amp; risk$si05 == 1, 2,
             ifelse(risk$si01 == 2 &amp; risk$si03 == 2 &amp; risk$si05 == 2, 1,
             NA)))))
qplot(risk$riskA[risk$riskA != 5])</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 3882 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/select%20risk%20taking%20data-1.png" width="672" /></p>
<pre class="r"><code>## calculate a risk score for risk game B 
# (5 = gamble averse, Ordinalskala : 1 = risk loving, 4 = risk averse)
risk$riskB = ifelse(risk$si11 == 2 &amp; risk$si12 == 1, 5,
             ifelse(risk$si11 == 1 &amp; risk$si13 == 1 &amp; risk$si14 == 1, 4,
             ifelse(risk$si11 == 1 &amp; risk$si13 == 1 &amp; risk$si14 == 2, 3,
             ifelse(risk$si11 == 1 &amp; risk$si13 == 2 &amp; risk$si15 == 1, 2,
             ifelse(risk$si11 == 1 &amp; risk$si13 == 2 &amp; risk$si15 == 2, 1,
             NA)))))
qplot(risk$riskB[risk$riskB !=5])</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 2084 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/select%20risk%20taking%20data-2.png" width="672" /></p>
<pre class="r"><code>psych::alpha(data.frame(risk %&gt;% select(riskA, riskB)), check.keys = T)</code></pre>
<pre><code>## Warning in matrix(unlist(drop.item), ncol = 8, byrow = TRUE): data length
## [12] is not a sub-multiple or multiple of the number of columns [8]</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = data.frame(risk %&gt;% select(riskA, riskB)), check.keys = T)
## 
##   raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd
##       0.29      0.33     0.2       0.2 0.5 0.0067  3.6 0.96
## 
##  lower alpha upper     95% confidence boundaries
## 0.28 0.29 0.3 
## 
##  Reliability if an item is dropped:
##       raw_alpha std.alpha G6(smc) average_r S/N alpha se
## riskA      0.20       0.2    0.04       0.2  NA       NA
## riskB      0.04       0.2      NA        NA 0.2   0.0025
## 
##  Item statistics 
##           n raw.r std.r r.cor r.drop mean   sd
## riskA 27780  0.90  0.77  0.35    0.2  3.4 1.51
## riskB 29578  0.64  0.77  0.35    0.2  3.9 0.82
## 
## Non missing response frequency for each item
##          1    2    3    4    5 miss
## riskA 0.19 0.12 0.11 0.24 0.33 0.12
## riskB 0.04 0.02 0.11 0.70 0.13 0.07</code></pre>
</div>
<div id="merge-data" class="section level2">
<h2>Merge data</h2>
<pre class="r"><code>### Merge ALL data (including all participants)
alldata = full_join(individuals_parents_checked, iq, by=&quot;pidlink&quot;)
alldata = full_join(alldata, pers, by=&quot;pidlink&quot;)
alldata = full_join(alldata, risk, by=&quot;pidlink&quot;)

### Merge PARENTS_CHECKED Data
#alldata_parents_checked = left_join(individuals_parents_checked, iq, by=&quot;pidlink&quot;)
#alldata_parents_checked = left_join(alldata_parents_checked, pers, by=&quot;pidlink&quot;)
#alldata_parents_checked = left_join(alldata_parents_checked, risk, by=&quot;pidlink&quot;)

#table(is.na(alldata_parents_checked$big5_ext))</code></pre>
</div>
<div id="calculate-age-related-t-scores" class="section level2">
<h2>Calculate age related t-scores</h2>
<pre class="r"><code>qplot(data = alldata, factor(age), raven, geom = &quot;blank&quot;) + stat_summary( fun.data = &quot;mean_sdl&quot;)</code></pre>
<pre><code>## Warning: Removed 6762 rows containing non-finite values (stat_summary).</code></pre>
<p><img src="1_data_import_files/figure-html/Calculate%20age%20related%20t-scores-1.png" width="672" /></p>
<pre class="r"><code>### IQ
alldata$raven_t &lt;- 10*ave(alldata$raven, alldata$age, FUN=scale) + 50
qplot(alldata$raven_t)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 6762 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/Calculate%20age%20related%20t-scores-2.png" width="672" /></p>
<pre class="r"><code>alldata$math_t &lt;- 10*ave(alldata$math, alldata$age, FUN=scale) + 50
qplot(alldata$math_t)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 6762 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/Calculate%20age%20related%20t-scores-3.png" width="672" /></p>
<pre class="r"><code>alldata$count_backwards_t &lt;- 10*ave(alldata$count_backwards, alldata$age, FUN=scale) + 50
qplot(alldata$count_backwards_t)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 1712 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/Calculate%20age%20related%20t-scores-4.png" width="672" /></p>
<pre class="r"><code>alldata$words_immediate_t &lt;- 10*ave(alldata$words_immediate, alldata$age, FUN=scale) + 50
qplot(alldata$words_immediate_t)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 6631 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/Calculate%20age%20related%20t-scores-5.png" width="672" /></p>
<pre class="r"><code>alldata$words_delayed_t &lt;- 10*ave(alldata$words_delayed, alldata$age, FUN=scale) + 50
qplot(alldata$words_delayed_t)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 6631 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/Calculate%20age%20related%20t-scores-6.png" width="672" /></p>
<pre class="r"><code>alldata$adaptive_numbering_t &lt;- 10*ave(alldata$adaptive_numbering, alldata$age, FUN=scale) + 50
qplot(alldata$adaptive_numbering_t)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 6693 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/Calculate%20age%20related%20t-scores-7.png" width="672" /></p>
<pre class="r"><code>### Personality
alldata$big5_ext_t &lt;- 10*ave(alldata$big5_ext, alldata$age, FUN=scale) + 50
qplot(alldata$big5_ext_t)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 6658 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/Calculate%20age%20related%20t-scores-8.png" width="672" /></p>
<pre class="r"><code>alldata$big5_agree_t &lt;- 10*ave(alldata$big5_agree, alldata$age, FUN=scale) + 50
qplot(alldata$big5_agree_t)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 6656 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/Calculate%20age%20related%20t-scores-9.png" width="672" /></p>
<pre class="r"><code>alldata$big5_open_t &lt;- 10*ave(alldata$big5_open, alldata$age, FUN=scale) + 50
qplot(alldata$big5_open_t)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 6656 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/Calculate%20age%20related%20t-scores-10.png" width="672" /></p>
<pre class="r"><code>alldata$big5_con_t &lt;- 10*ave(alldata$big5_con, alldata$age, FUN=scale) + 50
qplot(alldata$big5_con_t)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 6656 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/Calculate%20age%20related%20t-scores-11.png" width="672" /></p>
<pre class="r"><code>alldata$big5_neu_t &lt;- 10*ave(alldata$big5_neu, alldata$age, FUN=scale) + 50
qplot(alldata$big5_neu_t)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 6656 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="1_data_import_files/figure-html/Calculate%20age%20related%20t-scores-12.png" width="672" /></p>
<pre class="r"><code>###Risktaking (geht nicht, da es keine intervallskalierte Variable ist (nur 5 level))</code></pre>
</div>
<div id="exploring-data" class="section level2">
<h2>Exploring data</h2>
<pre class="r"><code>### Birth order and sibling size
ggplot(alldata, aes(x=siblingcount, y=birthorder)) + geom_jitter()</code></pre>
<pre><code>## Warning: Removed 29816 rows containing missing values (geom_point).</code></pre>
<p><img src="1_data_import_files/figure-html/exploring%20data-1.png" width="672" /></p>
<pre class="r"><code>### Birth order and age
ggplot(alldata, aes(x=birthorder, y=age)) + geom_jitter() + coord_cartesian(ylim = c(0, 100))</code></pre>
<pre><code>## Warning: Removed 29816 rows containing missing values (geom_point).</code></pre>
<p><img src="1_data_import_files/figure-html/exploring%20data-2.png" width="672" /></p>
<pre class="r"><code>### Personality
ggplot(alldata, aes(x=big5_agree, y=big5_neu)) + geom_jitter()</code></pre>
<pre><code>## Warning: Removed 6656 rows containing missing values (geom_point).</code></pre>
<p><img src="1_data_import_files/figure-html/exploring%20data-3.png" width="672" /></p>
<pre class="r"><code>###Openness and Intelligence
round(cor(alldata %&gt;% ungroup %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering, g_factor, big5_open), use = &quot;pairwise.complete.obs&quot;), 2)</code></pre>
<pre><code>##                    raven math count_backwards words_immediate
## raven               1.00 0.41            0.32            0.38
## math                0.41 1.00            0.26            0.31
## count_backwards     0.32 0.26            1.00            0.33
## words_immediate     0.38 0.31            0.33            1.00
## words_delayed       0.37 0.31            0.30            0.77
## adaptive_numbering  0.45 0.35            0.40            0.40
## g_factor            0.77 0.63            0.60            0.61
## big5_open           0.15 0.13            0.12            0.17
##                    words_delayed adaptive_numbering g_factor big5_open
## raven                       0.37               0.45     0.77      0.15
## math                        0.31               0.35     0.63      0.13
## count_backwards             0.30               0.40     0.60      0.12
## words_immediate             0.77               0.40     0.61      0.17
## words_delayed               1.00               0.37     0.64      0.15
## adaptive_numbering          0.37               1.00     0.79      0.16
## g_factor                    0.64               0.79     1.00      0.20
## big5_open                   0.15               0.16     0.20      1.00</code></pre>
<pre class="r"><code>###Other personality factors and Intelligence
round(cor(alldata %&gt;% ungroup %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering, g_factor, big5_con), use = &quot;pairwise.complete.obs&quot;), 2)</code></pre>
<pre><code>##                    raven  math count_backwards words_immediate
## raven               1.00  0.41            0.32            0.38
## math                0.41  1.00            0.26            0.31
## count_backwards     0.32  0.26            1.00            0.33
## words_immediate     0.38  0.31            0.33            1.00
## words_delayed       0.37  0.31            0.30            0.77
## adaptive_numbering  0.45  0.35            0.40            0.40
## g_factor            0.77  0.63            0.60            0.61
## big5_con            0.00 -0.01            0.03            0.03
##                    words_delayed adaptive_numbering g_factor big5_con
## raven                       0.37               0.45     0.77     0.00
## math                        0.31               0.35     0.63    -0.01
## count_backwards             0.30               0.40     0.60     0.03
## words_immediate             0.77               0.40     0.61     0.03
## words_delayed               1.00               0.37     0.64     0.01
## adaptive_numbering          0.37               1.00     0.79     0.02
## g_factor                    0.64               0.79     1.00     0.02
## big5_con                    0.01               0.02     0.02     1.00</code></pre>
<pre class="r"><code>round(cor(alldata %&gt;% ungroup %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering, g_factor, big5_ext), use = &quot;pairwise.complete.obs&quot;), 2)</code></pre>
<pre><code>##                    raven math count_backwards words_immediate
## raven               1.00 0.41            0.32            0.38
## math                0.41 1.00            0.26            0.31
## count_backwards     0.32 0.26            1.00            0.33
## words_immediate     0.38 0.31            0.33            1.00
## words_delayed       0.37 0.31            0.30            0.77
## adaptive_numbering  0.45 0.35            0.40            0.40
## g_factor            0.77 0.63            0.60            0.61
## big5_ext            0.07 0.06            0.08            0.09
##                    words_delayed adaptive_numbering g_factor big5_ext
## raven                       0.37               0.45     0.77     0.07
## math                        0.31               0.35     0.63     0.06
## count_backwards             0.30               0.40     0.60     0.08
## words_immediate             0.77               0.40     0.61     0.09
## words_delayed               1.00               0.37     0.64     0.08
## adaptive_numbering          0.37               1.00     0.79     0.08
## g_factor                    0.64               0.79     1.00     0.11
## big5_ext                    0.08               0.08     0.11     1.00</code></pre>
<pre class="r"><code>round(cor(alldata %&gt;% ungroup %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering, g_factor, big5_agree), use = &quot;pairwise.complete.obs&quot;), 2)</code></pre>
<pre><code>##                    raven  math count_backwards words_immediate
## raven               1.00  0.41            0.32            0.38
## math                0.41  1.00            0.26            0.31
## count_backwards     0.32  0.26            1.00            0.33
## words_immediate     0.38  0.31            0.33            1.00
## words_delayed       0.37  0.31            0.30            0.77
## adaptive_numbering  0.45  0.35            0.40            0.40
## g_factor            0.77  0.63            0.60            0.61
## big5_agree         -0.03 -0.02            0.01            0.01
##                    words_delayed adaptive_numbering g_factor big5_agree
## raven                       0.37               0.45     0.77      -0.03
## math                        0.31               0.35     0.63      -0.02
## count_backwards             0.30               0.40     0.60       0.01
## words_immediate             0.77               0.40     0.61       0.01
## words_delayed               1.00               0.37     0.64      -0.01
## adaptive_numbering          0.37               1.00     0.79      -0.01
## g_factor                    0.64               0.79     1.00      -0.02
## big5_agree                 -0.01              -0.01    -0.02       1.00</code></pre>
<pre class="r"><code>round(cor(alldata %&gt;% ungroup %&gt;% select(raven, math, count_backwards, words_immediate, words_delayed, adaptive_numbering, g_factor, big5_neu), use = &quot;pairwise.complete.obs&quot;), 2)</code></pre>
<pre><code>##                    raven math count_backwards words_immediate
## raven               1.00 0.41            0.32            0.38
## math                0.41 1.00            0.26            0.31
## count_backwards     0.32 0.26            1.00            0.33
## words_immediate     0.38 0.31            0.33            1.00
## words_delayed       0.37 0.31            0.30            0.77
## adaptive_numbering  0.45 0.35            0.40            0.40
## g_factor            0.77 0.63            0.60            0.61
## big5_neu            0.01 0.02           -0.01           -0.02
##                    words_delayed adaptive_numbering g_factor big5_neu
## raven                       0.37               0.45     0.77     0.01
## math                        0.31               0.35     0.63     0.02
## count_backwards             0.30               0.40     0.60    -0.01
## words_immediate             0.77               0.40     0.61    -0.02
## words_delayed               1.00               0.37     0.64     0.00
## adaptive_numbering          0.37               1.00     0.79     0.00
## g_factor                    0.64               0.79     1.00     0.01
## big5_neu                    0.00               0.00     0.01     1.00</code></pre>
<pre class="r"><code># Opennes has the highest values!
ggplot(alldata, aes(x=big5_open, y=g_factor)) + geom_jitter() + geom_smooth(method=lm) </code></pre>
<pre><code>## Warning: Removed 7102 rows containing non-finite values (stat_smooth).</code></pre>
<pre><code>## Warning: Removed 7102 rows containing missing values (geom_point).</code></pre>
<p><img src="1_data_import_files/figure-html/exploring%20data-4.png" width="672" /></p>
</div>
<div id="save-data" class="section level2">
<h2>Save data</h2>
<p>for future analyses</p>
<pre class="r"><code>saveRDS(alldata, file = &quot;data/hh14_all_dta/alldata.dta&quot;)</code></pre>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
